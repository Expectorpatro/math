\section{正态分布}
\begin{definition}
	若随机变量$X$的概率函数为：
	\begin{equation*}
		f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2}\right\}
	\end{equation*}
	则称其服从均值为$\mu$、方差为$\sigma^2$的\textbf{正态分布}，记作$X\sim\operatorname{N}(\mu,\sigma^2)$。
\end{definition}
\subsection{多元正态分布}
\begin{definition}\label{def:MultiNormal}
	$\mathbf{X}$为$n$维随机向量。若存在矩阵$A\in M_{n\times r}(\mathbb{R})$使得$\mathbf{X}=A\mathbf{U}+\boldsymbol{\mu}$，其中$\mathbf{U}=(\mathbf{U}_1,\mathbf{U}_2,\dots,\mathbf{U}_r)^T,\;\mathbf{U}_i\sim N(0,1)$且相互独立，$\boldsymbol{\mu}$为$n$维非随机实向量，则称$\mathbf{X}$为服从均值为$\boldsymbol{\mu}$、协方差矩阵为$\Sigma=AA^T$的多元正态向量，记为$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma)$，其中$\Sigma\geqslant\mathbf{0}$。若$|\Sigma|=0$，则称此时的分布为\textbf{奇异正态分布}。
\end{definition}
\begin{note}
	因为由\info{期望的性质}和\cref{prop:CovMat}(3)(4)(5)可得$\operatorname{E}(\mathbf{X})=\boldsymbol{\mu},\;\operatorname{Cov}(\mathbf{X})=AA^T$，所以上定义成立。
\end{note}
\begin{property}\label{prop:MultiNormal}
	多元正态分布具有如下性质：
	\begin{enumerate}
		\item 设$\mathbf{X}\sim\operatorname{N}_n(\boldsymbol{\mu},\Sigma),\Sigma\geqslant\mathbf{0}$，则当$\Sigma>\mathbf{0}$时，$\mathbf{X}$的概率函数为：
		\begin{align*}
			p(\mathbf{X})&=\frac{1}{(2\pi)^{\frac{n}{2}}(\det\Sigma)^{\frac{1}{2}}}\exp\left\{-\frac{1}{2}(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{X}-\boldsymbol{\mu})\right\} \\
			&=\frac{1}{(2\pi)^{\frac{n}{2}}(\det\Sigma)^{\frac{1}{2}}}\exp\{-\frac{1}{2}\operatorname{tr}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}]\}
		\end{align*}
		当$\det\Sigma=0$时，记$\operatorname{rank}(\Sigma)=r$，$\Sigma$的非零特征值为$\seq{\lambda}{r}$，则$\mathbf{X}-\boldsymbol{\mu}$以概率为$1$落在$\mathcal{M}(\Sigma)$中，且在该子空间内有概率函数：
		\begin{equation*}
			p(\mathbf{X})=(2\pi)^{-\frac{r}{2}}\left(\prod\limits_{i=1}^r\lambda_i\right)^{-\frac{1}{2}}\exp\left\{-\frac{1}{2}(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^-(\mathbf{X}-\boldsymbol{\mu})\right\}
		\end{equation*}
		\item 设$\mathbf{X}\sim\operatorname{N}_n(\boldsymbol{\mu},\Sigma),\Sigma\geqslant\mathbf{0}$，$B\in M_{m\times n}(\mathbb{R}),\;c\in\mathbb{R}^{n}$，则$\mathbf{Y}=B\mathbf{X}+c\sim N(B\boldsymbol{\mu}+c,B\Sigma B^T)$；
		\item 设$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma),\;\boldsymbol{\mu}=(\seq{\mu}{n})^T,\;\Sigma=(\sigma_{ij})$，$i_1<i_2<\cdots<i_k,\;k\leqslant n$，则有$(\mathbf{X}_{i_1},\mathbf{X}_{i_2},\dots,\mathbf{X}_{i_k})^T\sim N(\boldsymbol{\mu}_0,\Sigma_0)$，其中：
		\begin{equation*}
			\boldsymbol{\mu}_0=
			\begin{pmatrix}
				\mu_{i_1} \\
				\mu_{i_2} \\
				\vdots \\
				\mu_{i_k}
			\end{pmatrix}
			,\quad
			\Sigma_0=
			\begin{pmatrix}
				\sigma_{i_1i_1} & \sigma_{i_1i_2} & \cdots & \sigma_{i_1i_k} \\
				\sigma_{i_2i_1} & \sigma_{i_2i_2} & \cdots & \sigma_{i_2i_k} \\
				\vdots & \vdots & \ddots & \vdots \\
				\sigma_{i_ki_1} & \sigma_{i_ki_2} & \cdots & \sigma_{i_ki_k}
			\end{pmatrix}
		\end{equation*}
		\item 设$\mathbf{X}$是一个$n$维随机向量，则$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma)$当且仅当它的特征函数为：
		\begin{equation*}
			\varphi_\mathbf{X}(t)=\exp\left(it^T\boldsymbol{\mu}-\frac{t^T\Sigma t}{2}\right),\;t\in\mathbb{R}^{n}
		\end{equation*}
		\item 设$\mathbf{X}$是一个$n$维随机向量，则$\mathbf{X}$服从$n$维多元正态分布的充分必要条件为对于任意的$\alpha\in\mathbb{R}^{n}$，$\alpha^T\mathbf{X}$服从正态分布；
		\item 设$\mathbf{X}\sim\operatorname{N}_m(\boldsymbol{\mu}_1,\Sigma_1)$和$\mathbf{Y}\sim\operatorname{N}_n(\boldsymbol{\mu}_2,\Sigma_2)$独立，则：
		\begin{equation*}
			\mathbf{Z}=
			\begin{pmatrix}
				\mathbf{X} \\
				\mathbf{Y}
			\end{pmatrix}
			\sim N_{m+n}\left[
			\begin{pmatrix}
				\boldsymbol{\mu}_{1} \\
				\boldsymbol{\mu}_{2}
			\end{pmatrix},\;
			\begin{pmatrix}
				\Sigma_1 & \mathbf{0} \\
				\mathbf{0} & \Sigma_2
			\end{pmatrix}
			\right]
		\end{equation*}
		\item 设$\mathbf{X}\sim N_n(\boldsymbol{\mu}_1,\Sigma_1)$和$\mathbf{Y}\sim N_n(\boldsymbol{\mu}_2,\Sigma_2)$独立，则$\mathbf{X}+\mathbf{Y}\sim N_n(\boldsymbol{\mu}+\boldsymbol{\nu},\Sigma_\mathbf{X}+\Sigma_\mathbf{Y})$；
		\item 设$\mathbf{X_j}\sim\operatorname{N}_{r_j}(\boldsymbol{\mu_j},\Sigma_{j}),\;j=1,2,\dots,m$，$\mathbf{X_j}$的联合分布为正态分布。若$\mathbf{X_j}$不相关，则$\mathbf{X_j}$相互独立，即对于服从多维正态分布的随机向量而言，若它们的联合分布仍是多维正态分布，则不相关和独立等价；
		\item 设$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma)$，$\Sigma>\mathbf{0}$，则$(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{X}-\boldsymbol{\mu})\sim\chi_n^2$。
	\end{enumerate}
\end{property}
\begin{proof}
	(1)\textbf{当$\Sigma>\mathbf{0}$时：}因为$\Sigma$是实对称矩阵且$\Sigma>\mathbf{0}$，所以$\Sigma^{\frac{1}{2}},\Sigma^{-\frac{1}{2}}$存在，可将$\mathbf{X}$表示为$\mathbf{X}=\Sigma^{\frac{1}{2}}\mathbf{Y}+\boldsymbol{\mu}$，其中$\mathbf{Y}$是由相互独立的服从标准正态分布的随机变量构成的$n$维随机向量，有分布函数：
	\begin{equation*}
		p(\mathbf{Y})=\prod_{i=1}^{n}\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{\mathbf{Y}_i^2}{2}\right)=\frac{1}{(2\pi)^{\frac{n}{2}}}\exp\left(-\frac{1}{2}\mathbf{Y}^T\mathbf{Y}\right)
	\end{equation*}
	由求随机变量函数的分布中的变量变换法可知\info{随机变量函数分布的变量变换法，逆矩阵的行列式，正定矩阵的行列式，矩阵乘积的行列式，逆平方根阵的对称性，矩阵乘积的转置}：
	\begin{align*}
		&p(\mathbf{X})=p[\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu})]|\det\Sigma^{-\frac{1}{2}}| \\
		=&\frac{1}{(2\pi)^{\frac{n}{2}}(\det\Sigma)^\frac{1}{2}}\exp\left\{-\frac{1}{2}[\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu})]^T[\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu})]\right\} \\
		=&\frac{1}{(2\pi)^{\frac{n}{2}}(\det\Sigma)^{\frac{1}{2}}}\exp\left\{-\frac{1}{2}(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{X}-\boldsymbol{\mu})\right\}
	\end{align*}
	只需注意到二次型的迹就是自身以及\cref{prop:Trace}(3)就有：
	\begin{equation*}
		(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{X}-\boldsymbol{\mu})=\operatorname{tr}[(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{X}-\boldsymbol{\mu})]=\operatorname{tr}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}]
	\end{equation*}\par
	\textbf{当$\det\Sigma=0$时：}\par
	(2)因为$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma)$，所以存在$A\in M_{n\times r}(\mathbb{R}),\;\boldsymbol{\mu}\in\mathbb{R}^{n}$使得：
	\begin{equation*}
		\mathbf{X}=A\mathbf{U}+\boldsymbol{\mu},\;AA^T=\Sigma,\;U\sim N(\mathbf{0},I)
	\end{equation*}
	于是：
	\begin{equation*}
		\mathbf{Y}=B(A\mathbf{U}+\boldsymbol{\mu})+c=BA\mathbf{U}+B\boldsymbol{\mu}+c
	\end{equation*}
	注意到$BA(BA)^T=BAA^TB^T=B\Sigma B^T$，所以$\mathbf{Y}\sim N(B\boldsymbol{\mu}+c,B\Sigma B^T)$。\par
	(3)取$A=(e_{i_1}^T;e_{i_2}^T;\cdots;e_{i_k}^T)$，其中$e_{i_j}$为单位列向量，只在第$i_j$位取$1$，其余位置上元素为$0$，$j=1,2,\dots,k$，于是有：
	\begin{gather*}
		A\boldsymbol{\mu}=(\mu_{i_i},\mu_{i_2},\dots,\mu_{i_k})^T=\boldsymbol{\mu}_0
		\\
		A\Sigma A^T=
		\begin{pmatrix}
			e_{i_1}^T\Sigma e_{i_1} & e_{i_1}^T\Sigma e_{i_2} & \cdots & e_{i_1}^T\Sigma e_{i_k} \\
			e_{i_2}^T\Sigma e_{i_1} & e_{i_2}^T\Sigma e_{i_2} & \cdots & e_{i_2}^T\Sigma e_{i_k} \\
			\vdots & \vdots & \ddots & \vdots \\
			e_{i_k}^T\Sigma e_{i_1} & e_{i_k}^T\Sigma e_{i_2} & \cdots & e_{i_k}^T\Sigma e_{i_k}^T
		\end{pmatrix}
		=
		\begin{pmatrix}
			\sigma_{i_1i_1} & \sigma_{i_1i_2} & \cdots & \sigma_{i_1i_k} \\
			\sigma_{i_2i_1} & \sigma_{i_2i_2} & \cdots & \sigma_{i_2i_k} \\
			\vdots & \vdots & \ddots & \vdots \\
			\sigma_{i_ki_1} & \sigma_{i_ki_2} & \cdots & \sigma_{i_ki_k}
		\end{pmatrix}
		=\Sigma_0
	\end{gather*}
	由(2)可得$(\mathbf{X}_{i_1},\mathbf{X}_{i_2},\dots,\mathbf{X}_{i_k})^T\sim N(\boldsymbol{\mu}_0,\Sigma_0)$。\par
	(4)	若$X\sim N_n(\boldsymbol{\mu},\Sigma)$，则存在矩阵$A\in M_{n\times r}(\mathbb{R})$使得$\mathbf{X}=A\mathbf{U}+\boldsymbol{\mu}$，其中$\mathbf{U}=(\mathbf{U}_1,\mathbf{U}_2,\dots,\mathbf{U}_r)^T$，$\mathbf{U}_i\sim N(0,1)$且互相独立，$\boldsymbol{\mu}$为$n$维非随机实向量，$\Sigma=AA^T$。由\cref{prop:CharacteristicFunction}(5)可得\info{需要证明1维正态分布的特征函数}：
	\begin{equation*}
		\varphi_\mathbf{U}(t)=\prod_{i=1}^n\varphi_{\mathbf{U}_i}(t_i)
		=\prod_{i=1}^ne^{-\frac{t_i^2}{2}}=e^{-\frac{t^Tt}{2}},\;t\in\mathbb{R}^{n}
	\end{equation*}
	于是：
	\begin{align*}
		\varphi_\mathbf{X}(t)
		&=\operatorname{E}(e^{it^T\mathbf{X}})
		=\operatorname{E}[e^{it^T(A\mathbf{U}+\boldsymbol{\mu})}]
		=e^{it\boldsymbol{\mu}}\operatorname{E}(e^{it^TA\mathbf{U}}) \\
		&=e^{it^T\boldsymbol{\mu}}\varphi_\mathbf{U}(A^Tt)
		=e^{it^T\boldsymbol{\mu}}e^{-\frac{t^TAA^Tt}{2}}
		=e^{it^T\boldsymbol{\mu}}e^{-\frac{t^T\Sigma t}{2}}
		=\exp\left(it^T\boldsymbol{\mu}-\frac{t^T\Sigma t}{2}\right)
	\end{align*}
	由\cref{prop:CharacteristicFunction}(6)可知结论成立。\par
	(5)\textbf{(必要性：}由(2)直接得到。\par
	\textbf{充分性：}由(4)可知此时$\alpha^T\mathbf{X}$的特征函数为：
	\begin{equation*}
		\varphi_{\alpha^T\mathbf{X}}(t)=\exp\left(it\mu-\frac{1}{2}t^2\sigma^2\right)
	\end{equation*}
	其中$\mu$和$\sigma^2$分别为$\alpha^T\mathbf{X}$的均值与方差。由\info{期望的性质}和\cref{prop:CovMat}(3)可得：
	\begin{gather*}
		\mu=\operatorname{E}(\alpha^T\mathbf{X})=\alpha^T\operatorname{E}(\mathbf{X}),\;
		\sigma^2=\operatorname{Cov}(\alpha^T\mathbf{X})=\alpha^T\operatorname{Cov}(\mathbf{X})\alpha
	\end{gather*}
	于是有：
	\begin{equation*}
		\varphi_{\alpha^T\mathbf{X}}(t)=\exp\left[it\alpha^T\operatorname{E}(\mathbf{X})-\frac{t\alpha^T\operatorname{Cov}(\mathbf{X})\alpha t}{2}\right]
	\end{equation*}
	由$\alpha$的任意性，上式可写作：
	\begin{equation*}
		\varphi_{\mathbf{X}}(\beta)=\exp\left[i\beta^T\operatorname{E}(\mathbf{X})-\frac{\beta^T\operatorname{Cov}(\mathbf{X})\beta}{2}\right]
	\end{equation*}
	由\cref{prop:CharacteristicFunction}(6)和(4)可知$\mathbf{X}$服从多元正态分布。\par
	(6)由\cref{def:MultiNormal}可得。\par
	(7)	因为：
	\begin{equation*}
		\mathbf{X}+\mathbf{Y}=
		\begin{pmatrix}
			I_n & I_n
		\end{pmatrix}
		\begin{pmatrix}
			\mathbf{X} \\
			\mathbf{Y}
		\end{pmatrix}
	\end{equation*}
	由(6)可得：
	\begin{equation*}
		\mathbf{Z}=
		\begin{pmatrix}
			\mathbf{X} \\
			\mathbf{Y}
		\end{pmatrix}
		\sim N_{2n}\left[
		\begin{pmatrix}
			\boldsymbol{\mu}_1 \\
			\boldsymbol{\mu}_2
		\end{pmatrix},\;
		\begin{pmatrix}
			\Sigma_1 & \mathbf{0} \\
			\mathbf{0} & \Sigma_2
		\end{pmatrix}
		\right]
	\end{equation*}
	根据(2)即可得到结论。\par
	(8)设$\mathbf{X}=(\mathbf{X_1},\mathbf{X_2},\dots,\mathbf{X_m})^T\sim\operatorname{N}_n(\boldsymbol{\mu},\Sigma)$。因为$\mathbf{X_j}$之间不相关，于是：
	\begin{equation*}
		\boldsymbol{\mu}=
		\begin{pmatrix}
			\boldsymbol{\mu_1} \\
			\boldsymbol{\mu_2} \\
			\cdots \\
			\boldsymbol{\mu_m}
		\end{pmatrix},\quad
		\Sigma=
		\begin{pmatrix}
			\Sigma_1 & \mathbf{0} & \cdots & \mathbf{0} \\
			\mathbf{0} & \Sigma_2 & \cdots & \mathbf{0} \\
			\vdots & \vdots & \ddots & \vdots \\
			\mathbf{0} & \mathbf{0} & \cdots & \Sigma_m
		\end{pmatrix}
	\end{equation*}
	由(4)可得：
	\begin{align*}
		\varphi_\mathbf{X}(t)
		&=\exp\left(it\boldsymbol{\mu}-\frac{t^T\Sigma t}{2}\right)
		=\exp\left(i\sum_{j=1}^{m}t_j^T\boldsymbol{\mu_j}-\frac{\sum\limits_{j=1}^{m}t_j^T\Sigma_j t_j}{2}\right) \\
		&=\prod_{j=1}^m\exp\left(it_j\boldsymbol{\mu_j}-\frac{t_j^T\Sigma_j t_j}{2}\right)=\prod_{j=1}^m\varphi_\mathbf{X_j}(t_j)
	\end{align*}
	由\cref{prop:CharacteristicFunction}(5)可知$\mathbf{X_j}$相互独立，$j=1,2,\dots,m$。\par
	(9)因为$\Sigma>\mathbf{0}$，所以存在$\Sigma^{-\frac{1}{2}}$。由(2)可得：
	\begin{equation*}
		\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu})\sim N_n(\mathbf{0},I_n)
	\end{equation*}
	于是根据\cref{prop:ReverseSquareRootMat}(1)和(3)可得：
	\begin{align*}
		(\mathbf{X}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{X}-\boldsymbol{\mu})&=(\mathbf{X}-\boldsymbol{\mu})^T(\Sigma^{-\frac{1}{2}}\Sigma^{-\frac{1}{2}})(\mathbf{X}-\boldsymbol{\mu}) =(\mathbf{X}-\boldsymbol{\mu})^T(\Sigma^{-\frac{1}{2}})^T\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu}) \\
		&=[\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu})]^T\Sigma^{-\frac{1}{2}}(\mathbf{X}-\boldsymbol{\mu})\sim\chi_n^2\qedhere
	\end{align*}
\end{proof}
\subsubsection{正态随机向量的二次型}
\begin{theorem}
	设$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma),\;\Sigma>\mathbf{0}$，$A$为$n$阶非随机实对称阵，则：
	\begin{equation*}
		\operatorname{E}(\mathbf{X}^TA\mathbf{X})=\boldsymbol{\mu}^TA\boldsymbol{\mu}+\operatorname{tr}(A\Sigma),\;
		\operatorname{Var}(\mathbf{X}^TA\mathbf{X})=2\operatorname{tr}[(A\Sigma)^2]+4\boldsymbol{\mu}^TA\Sigma A\boldsymbol{\mu}
	\end{equation*}
\end{theorem}
\begin{proof}
	期望可直接由\cref{theo:ERVQuadraticForm}得到。记$\mathbf{Y}=\Sigma^{-\frac{1}{2}}\mathbf{X}$，由\cref{prop:MultiNormal}(2)可知$\mathbf{Y}\sim N_n(\Sigma^{-\frac{1}{2}}\boldsymbol{\mu},I_n)$，根据\cref{prop:MultiNormal}(8)，$\mathbf{Y}$的各分量相互独立。注意到$\mathbf{Y}$的各分量的三阶中心矩和四阶中心矩分别为$0$和$3$，由\cref{theo:VRVQuadraticForm}、\cref{prop:ReverseSquareRootMat}(3)和\cref{prop:Trace}(3)可得：
	\begin{align*}
		\operatorname{Var}(\mathbf{X}^TA\mathbf{X})
		&=\operatorname{Var}(\mathbf{Y}^T\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\mathbf{Y}) \\
		&=3\sum_{i=1}^{n}(\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})_{ii}^2+2\operatorname{tr}(\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})-3\sum_{i=1}^{n}(\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})_{ii}^2 \\
		&\quad+4\boldsymbol{\mu}^T\Sigma^{-\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\boldsymbol{\mu} \\
		&=2\operatorname{tr}(\Sigma^{\frac{1}{2}}A\Sigma A\Sigma^{\frac{1}{2}})+4\boldsymbol{\mu}^TA\Sigma A\boldsymbol{\mu} \\
		&=2\operatorname{tr}(A\Sigma A\Sigma^{\frac{1}{2}}\Sigma^{\frac{1}{2}})+4\boldsymbol{\mu}^TA\Sigma A\boldsymbol{\mu} \\
		&=2\operatorname{tr}[(A\Sigma)^2]+4\boldsymbol{\mu}^TA\Sigma A\boldsymbol{\mu}\qedhere
	\end{align*}
\end{proof}
\begin{theorem}\label{theo:XAXChi2}
	设$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma),\;\Sigma>\mathbf{0}$，$A\in M_{n}(K)$是一个非随机实对称矩阵，则$\mathbf{X}^TA\mathbf{X}\sim\chi_{r,\boldsymbol{\mu}^TA\boldsymbol{\mu}}^2$的充分必要条件为$A\Sigma A=A$且$\operatorname{rank}(A)=r$。
\end{theorem}
\begin{proof}
	先证明$\Sigma=I_n$时的情况。\par
	\textbf{(1)充分性：}因为$A$是一个幂等阵，由\cref{prop:IdempotentMat}(1)可知$A$的特征值只能为$0$或$1$。根据\cref{prop:HermitianMatEigen}(3)可知存在正交矩阵$Q$使得：
	\begin{equation*}
		A=Q^{-1}
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}Q
	\end{equation*}
	令$\mathbf{Y}=Q\mathbf{X}$，由\cref{prop:MultiNormal}(2)可知$\mathbf{Y}\sim N_n(Q\boldsymbol{\mu},I_n)$。对$\mathbf{Y}$和$Q$进行分块：
	\begin{equation*}
		\mathbf{Y}=
		\begin{pmatrix}
			\mathbf{Y_1} \\
			\mathbf{Y_2}
		\end{pmatrix},\;
		Q=
		\begin{pmatrix}
			Q_1 \\
			Q_2
		\end{pmatrix}
	\end{equation*}
	其中$\mathbf{Y_1}$为$r$维随机向量，$Q_1$为$r\times n$矩阵，所以：
	\begin{align*}
		\mathbf{X}^TA\mathbf{X}&=\mathbf{X}^TQ^{-1}
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}Q\mathbf{X}=\mathbf{X}^TQ^T
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}Q\mathbf{X} \\
		&=\mathbf{Y}^T
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}\mathbf{Y}
		=
		\begin{pmatrix}
			\mathbf{Y_1}^T & \mathbf{Y_2}^T
		\end{pmatrix}
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		\begin{pmatrix}
			\mathbf{Y_1} \\
			\mathbf{Y_2}
		\end{pmatrix}
		=\mathbf{Y_1}^T\mathbf{Y_1}\sim\chi_{r,\lambda}^2
	\end{align*}
	其中：
	\begin{equation*}
		\lambda=(Q_1\boldsymbol{\mu})^TQ_1\boldsymbol{\mu}=\boldsymbol{\mu}^TQ_1^TQ_1\boldsymbol{\mu}=\boldsymbol{\mu}^TA\boldsymbol{\mu}
	\end{equation*}
	这是因为\cref{prop:MultiNormal}(3)和：
	\begin{equation*}
		A=Q^{-1}
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}Q
		=Q^T
		\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}Q
		=
		\begin{pmatrix}
			Q_1^T & Q_2^T
		\end{pmatrix}
			\begin{pmatrix}
			I_r & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		\begin{pmatrix}
			Q_1 \\
			Q_2
		\end{pmatrix}
		=Q_1^TQ_1
	\end{equation*}\par
	\textbf{(2)必要性：}设$\operatorname{rank}(A)=t$。因为$A$是实对称矩阵，由\cref{prop:HermitianMatEigen}(3)可知存在正交阵$Q$使得：
	\begin{equation*}
		A=Q^{-1}
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		Q
	\end{equation*}
	其中$\varLambda=\operatorname{diag}\{\seq{\lambda}{t}\}$，$\seq{\lambda}{t}$是$A$的非零特征值。若能证得$\lambda_i=1,\;i=1,2,\dots,t$且$t=r$，则$A$是一个幂等阵且$\operatorname{rank}(A)=r$。注意到：
	\begin{equation*}
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^TQ^T
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		Q\mathbf{X}
	\end{equation*}
	令$\mathbf{Y}=Q\mathbf{X}$，由\cref{prop:MultiNormal}(2)可知$\mathbf{Y}=(\seq{\mathbf{Y}}{n})\sim N_n(Q\boldsymbol{\mu},I_n)$，根据\cref{prop:MultiNormal}(8)可得$\mathbf{Y}_j$之间彼此独立。令$c=Q\boldsymbol{\mu}=(\seq{c}{n})^T$，由\cref{prop:MultiNormal}(3)可知$\mathbf{Y}_j\sim N(c_j,1)$。而：
	\begin{equation*}
		\mathbf{X}^TA\mathbf{X}=\mathbf{Y}^T
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}\mathbf{Y}=\sum_{j=1}^{t}\lambda_j\mathbf{Y}_j^2
	\end{equation*}
	由\cref{prop:CharacteristicFunction}(4)和\cref{prop:Chi2Distribution}(3)可知：
	\begin{align*}
		\varphi_{\mathbf{X}^TA\mathbf{X}}(t)
		&=\prod_{j=1}^{t}\varphi_{\lambda_j\mathbf{Y}_j^2}(t)=\prod_{j=1}^t(1-2it)^{-\frac{1}{2}}\exp\left\{\frac{i\lambda_jtc_j^2}{1-2i\lambda_jt}\right\} \\
		&=(1-2it)^{-\frac{t}{2}}\prod_{j=1}^t\exp\left\{\frac{i\lambda_jtc_j^2}{1-2i\lambda_jt}\right\}
	\end{align*}
	因为$\mathbf{X}^TA\mathbf{X}\sim\chi_{r,\boldsymbol{\mu}^TA\boldsymbol{\mu}}^2$，所以：
	\begin{equation*}
		\varphi_{\mathbf{X}^TA\mathbf{X}}(t)=(1-2it)^{-\frac{r}{2}}\exp\left\{\frac{it\boldsymbol{\mu}^TA\boldsymbol{\mu}}{1-2it}\right\}
	\end{equation*}
	由\cref{prop:CharacteristicFunction}(6)可知：
	\begin{equation*}
		(1-2it)^{-\frac{t}{2}}\prod_{j=1}^t\exp\left\{\frac{i\lambda_jtc_j^2}{1-2i\lambda_jt}\right\}=(1-2it)^{-\frac{r}{2}}\exp\left\{\frac{it\boldsymbol{\mu}^TA\boldsymbol{\mu}}{1-2it}\right\}
	\end{equation*}
	所以$t=r$，同时有：
	\begin{equation*}
		\sum_{j=1}^{t}\frac{i\lambda_jtc_j^2}{1-2i\lambda_jt}=\frac{it\boldsymbol{\mu}^TA\boldsymbol{\mu}}{1-2it}
	\end{equation*}
	即：
	\begin{gather*}
		\sum_{j=1}^{t}\frac{i\lambda_jtc_j^2}{1-2i\lambda_jt}=\frac{1}{1-2it}it\boldsymbol{\mu}^TQ^T
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		Q\boldsymbol{\mu} \\
		\sum_{j=1}^{t}\frac{\lambda_jc_j^2}{1-2i\lambda_jt}=\frac{1}{1-2it}c^T
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		c \\
		\sum_{j=1}^{t}\frac{\lambda_jc_j^2}{1-2i\lambda_jt}=\frac{1}{1-2it}\sum_{j=1}^{t}\lambda_jc_j^2 \\
		\frac{\lambda_jc_j^2}{1-2i\lambda_jt}=\frac{\lambda_jc_j^2}{1-2it},\;j=1,2,\dots,t
	\end{gather*}
	所以$\lambda_j=1$。\par
	当$\Sigma$为一般正定阵时，因为$\Sigma>\mathbf{0}$，所以存在$\Sigma^{-\frac{1}{2}}$。考虑随机向量$\mathbf{Y}=\Sigma^{-\frac{1}{2}}\mathbf{X}$，由\cref{prop:MultiNormal}(2)可知$\mathbf{Y}\sim N_n(\Sigma^{-\frac{1}{2}}\boldsymbol{\mu},I_n)$。注意到：
	\begin{equation*}
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^T\Sigma^{-\frac{1}{2}}\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}
	\end{equation*}
	由\cref{prop:ReverseSquareRootMat}(3)可得：
	\begin{equation*}
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^T(\Sigma^{-\frac{1}{2}})^T\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}=\mathbf{Y}\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\mathbf{Y}
	\end{equation*}
	由\cref{theo:XAXChi2}可得$\mathbf{Y}\Sigma
	^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\mathbf{Y}\sim\chi_{r,\boldsymbol{\mu}^TA\boldsymbol{\mu}}^2$的充分必要条件为$\Sigma
	^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}$是一个对称阵且：
	\begin{gather*}
		(\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})^2=\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}},\;
		\operatorname{rank}(\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})=r,\;
		(\Sigma^{-\frac{1}{2}}\boldsymbol{\mu})^T\Sigma^{\frac{1}{2}} A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\boldsymbol{\mu}=\boldsymbol{\mu}^TA\boldsymbol{\mu}
	\end{gather*}
	第三式显然成立。因为$\Sigma>\mathbf{0}$，所以$\operatorname{rank}(\Sigma
	^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})=\operatorname{rank}(A)$。注意到：
	\begin{align*}
		(\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}})^2=\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}&\Leftrightarrow
		\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}=\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}} \\
		&\Leftrightarrow
		\Sigma^{\frac{1}{2}}A\Sigma A\Sigma^{\frac{1}{2}}=\Sigma
		^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Leftrightarrow
		A\Sigma A=A\qedhere
	\end{align*}
\end{proof}
\begin{theorem}\label{theo:BXXAXIndependent}
	设$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma),\;\Sigma>\mathbf{0}$，$A\in M_{n}(\mathbb{R}^{})$是一个对称矩阵，$B\in M_{m\times n}(\mathbb{R}^{})$。若$B\Sigma A=\mathbf{0}$，则$B\mathbf{X}$与$\mathbf{X}^TA\mathbf{X}$相互独立。
\end{theorem}
\begin{proof}
	先证明$\Sigma=I_n$时的情况。\par
	因为$A$是一个实对称矩阵，由\cref{prop:HermitianMatEigen}(3)可知存在正交矩阵$Q$使得：
	\begin{equation*}
		Q^TAQ=
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
	\end{equation*}
	其中$\varLambda=\operatorname{diag}(\seq{\lambda}{r}),\;\lambda_i\ne0,\;i=1,2,\dots,r,\;\operatorname{rank}(A)=r$。因为$BA=\mathbf{0}$，所以有$BQQ^TAQ=BAQ=\mathbf{0}$，于是：
	\begin{equation*}
		BQ
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		=\mathbf{0}
	\end{equation*}
	设：
	\begin{equation*}
		C=BQ=
		\begin{pmatrix}
			C_{11} & C_{12} \\
			C_{21} & C_{22}
		\end{pmatrix}
	\end{equation*}
	则：
	\begin{equation*}
		BQ
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		=
		\begin{pmatrix}
			C_{11}\varLambda & \mathbf{0} \\
			C_{21}\varLambda & \mathbf{0}
		\end{pmatrix}
		=\begin{pmatrix}
			\mathbf{0} & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
	\end{equation*}
	于是有$C_{11}=\mathbf{0},\;C_{21}=\mathbf{0}$。对$C$和$Q$做对应分块：
	\begin{equation*}
		C=BQ=
		\begin{pmatrix}
			\mathbf{0} & C_1
		\end{pmatrix},\;
		Q=
		\begin{pmatrix}
			Q_1 & Q_2
		\end{pmatrix}
	\end{equation*}
	于是：
	\begin{equation*}
		B=CQ^T=
		\begin{pmatrix}
			\mathbf{0} & C_1
		\end{pmatrix}
		\begin{pmatrix}
			Q_1^T \\
			Q_2^T
		\end{pmatrix}
		=C_1Q_2^T
	\end{equation*}
	而：
	\begin{equation*}
		A=Q
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		Q^T
		=
		\begin{pmatrix}
			Q_1 & Q_2
		\end{pmatrix}
		\begin{pmatrix}
			\varLambda & \mathbf{0} \\
			\mathbf{0} & \mathbf{0}
		\end{pmatrix}
		\begin{pmatrix}
			Q_1^T \\
			Q_2^T
		\end{pmatrix}
		=Q_1\varLambda Q_1^T
	\end{equation*}
	记$\mathbf{Y}=Q^T\mathbf{X}$，由\cref{prop:MultiNormal}(2)可得：
	\begin{equation*}
		\mathbf{Y}=
		\begin{pmatrix}
			\mathbf{Y_1} \\
			\mathbf{Y_2}
		\end{pmatrix}
		=
		\begin{pmatrix}
			Q_1^T\mathbf{X} \\
			Q_2^T\mathbf{X}
		\end{pmatrix}
		\sim N_n(Q^T\boldsymbol{\mu},\sigma^2I_n)
	\end{equation*}
	由\cref{prop:MultiNormal}(8)可知$\mathbf{Y_1}$与$\mathbf{Y_2}$独立。因为：
	\begin{gather*}
		B\mathbf{X}=C_1Q_2^T\mathbf{X}=C_1\mathbf{Y_2} \\
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^TQ_1\varLambda Q_1^T\mathbf{X}=\mathbf{Y_1}^T\varLambda\mathbf{Y_1}
	\end{gather*}
	所以$B\mathbf{X}$与$\mathbf{X}^TA\mathbf{X}$独立，结论在$\Sigma=I_n$时成立。\par
	当$\Sigma$为一般正定阵时，存在$\Sigma^{-\frac{1}{2}}$。由\cref{prop:ReverseSquareRootMat}(3)和\cref{prop:MultiNormal}(2)可得此时有：
	\begin{gather*}
		\Sigma^{-\frac{1}{2}}\mathbf{X}\sim\operatorname{N}_n(\Sigma^{-\frac{1}{2}}\boldsymbol{\mu},I_n),\quad B\mathbf{X}=B\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X} \\
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^T\Sigma^{-\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}=(\Sigma^{-\frac{1}{2}}\mathbf{X})^T\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}
	\end{gather*}
	于是当：
	\begin{equation*}
		B\Sigma^{\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}=B\Sigma A\Sigma^{\frac{1}{2}}=\mathbf{0}
	\end{equation*}
	时，$B\mathbf{X}$与$\mathbf{X}^TA\mathbf{X}$相互独立，上式等式两边同时右乘$\Sigma^{-\frac{1}{2}}$即可得到其等价于$B\Sigma A=\mathbf{0}$。
\end{proof}
\begin{theorem}\label{theo:XAXXBXIndependent}
	设$\mathbf{X}\sim N_n(\boldsymbol{\mu},\Sigma)$，$A,B$为$n$阶实对称阵。若$A\Sigma B=\mathbf{0}$，则$\mathbf{X}^TA\mathbf{X}$与$\mathbf{X}^TB\mathbf{X}$独立。
\end{theorem}
\begin{proof}
	先证明$\Sigma=I_n$时的情况。\par
	因为$AB=\mathbf{0}$且$A,B$都是对称阵，所以$BA=B^TA^T=(AB)^T=\mathbf{0}$，即$AB=BA$，所以由\cref{prop:HermitianMatEigen}(3)可知存在正交矩阵$Q$可使得$A,B$同时对角化，即：
	\begin{equation*}
		Q^TAQ=\varLambda_1=\operatorname{diag}\{\seq{\lambda^{(1)}}{n}\},\quad Q^TBQ=\varLambda_2=\operatorname{diag}\{\seq{\lambda^{(2)}}{n}\}
	\end{equation*}
	因为$AB=\mathbf{0}$，所以：
	\begin{equation*}
		Q\varLambda_1Q^TQ\varLambda_2Q^T=Q\varLambda_1\varLambda_2Q^T=\mathbf{0}
	\end{equation*}
	等式两边先同时左乘$Q^T$再同时右乘$Q$即可得到$\varLambda_1\varLambda_2=\mathbf{0}$，即$\lambda_i^{(1)}$和$\lambda_i^{(2)}$中至少有一个为$0,\;i=1,2,\dots,n$。令$\mathbf{Y}=Q^T\mathbf{X}$，由\cref{prop:MultiNormal}(2)可得$\mathbf{Y}\sim\operatorname{N}_n(Q^T\boldsymbol{\mu},I_n)$，所以$\mathbf{Y}$的各分量相互独立。因为：
	\begin{equation*}
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^TQ\varLambda_1Q^T\mathbf{X}=\mathbf{Y}^T\varLambda_1\mathbf{Y},\quad\mathbf{X}^TB\mathbf{X}=\mathbf{X}^TQ\varLambda_2Q^T\mathbf{X}=\mathbf{Y}^T\varLambda_2\mathbf{Y}
	\end{equation*}
	二者依赖的$\mathbf{Y}$的分量不同，所以$\mathbf{X}^TA\mathbf{X}$与$\mathbf{X}^TB\mathbf{X}$独立。\par
	当$\Sigma$为一般正定矩阵时，存在$\Sigma^{-\frac{1}{2}}$。由\cref{prop:ReverseSquareRootMat}(3)和\cref{prop:MultiNormal}(2)可得此时有：
	\begin{gather*}
		\Sigma^{-\frac{1}{2}}\mathbf{X}\sim\operatorname{N}_n(\Sigma^{-\frac{1}{2}}\boldsymbol{\mu},I_n) \\
		\mathbf{X}^TA\mathbf{X}=\mathbf{X}^T\Sigma^{-\frac{1}{2}}\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}=(\Sigma^{-\frac{1}{2}}\mathbf{X})^T\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X} \\
		\mathbf{X}^TB\mathbf{X}=\mathbf{X}^T\Sigma^{-\frac{1}{2}}\Sigma^{\frac{1}{2}}B\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}=(\Sigma^{-\frac{1}{2}}\mathbf{X})^T\Sigma^{\frac{1}{2}}B\Sigma^{\frac{1}{2}}\Sigma^{-\frac{1}{2}}\mathbf{X}
	\end{gather*}
	于是当：
	\begin{equation*}
		\Sigma^{\frac{1}{2}}A\Sigma^{\frac{1}{2}}\Sigma^{\frac{1}{2}}B\Sigma^{\frac{1}{2}}=\Sigma^{\frac{1}{2}}A\Sigma B\Sigma^{\frac{1}{2}}=\mathbf{0}
	\end{equation*}
	时，$\mathbf{X}^TA\mathbf{X}$与$\mathbf{X}^TB\mathbf{X}$相互独立，上式等式两边同时左乘$\Sigma^{-\frac{1}{2}}$再右乘$\Sigma^{-\frac{1}{2}}$即可得到其等价于$B\Sigma A=\mathbf{0}$。
\end{proof}

\subsection{矩阵正态分布的定义}
\subsubsection{密度函数定义}
\begin{definition}\label{def:MatNormal1}
	若$m\times n$随机矩阵$\mathbf{X}$满足以下概率密度函数：
	\begin{equation*}
		p(\mathbf{X})=\frac{1}{(2\pi)^{\frac{mn}{2}}(\det U)^{\frac{n}{2}}(\det V)^{\frac{m}{2}}}e^{-\frac{1}{2}\operatorname{tr}[V^{-1}(X-M)^TU^{-1}(X-M)]}
	\end{equation*}
	其中，$M\in M_{m\times n}(\mathbb{R}),\;U\in M_{m}(\mathbb{R}),\;V\in M_{n}(\mathbb{R})$，$U,V>0$。此时称$\mathbf{X}$服从矩阵正态分布，记作$\mathbf{X}\sim MN(M,U,V)$。
\end{definition}
\subsubsection{向量化定义}
\begin{definition}\label{def:MatNormal2}
	若随机矩阵$\mathbf{X}$满足$\operatorname{vec}(\mathbf{X})\sim N(\operatorname{vec}(M),V\otimes U)$，其中，$M\in M_{m\times n}(\mathbb{R}),\;U\in M_{m}(\mathbb{R}),\;V\in M_{n}(\mathbb{R})$，$U,V\geqslant0$。此时称$\mathbf{X}$服从矩阵正态分布，记作$\mathbf{X}\sim MN(M,U,V)$。
\end{definition}
\begin{theorem}
	设$\mathbf{X}$是一个$m\times n$随机矩阵，其行协方差矩阵$U$和列协方差矩阵$V$都是正定矩阵，则$\mathbf{X}$满足\cref{def:MatNormal1}的充分必要条件为满足\cref{def:MatNormal2}。
\end{theorem}
\begin{proof}
	由\cref{prop:Trace}(3)、\cref{prop:VecOperator}(1)(2)、\cref{prop:Kronecker}(2)(3)可得：
	\begin{align*}
		\operatorname{tr}[V^{-1}(\mathbf{X}-M)^TU^{-1}(\mathbf{X}-M)]
		&=\operatorname{tr}[(\mathbf{X}-M)^TU^{-1}(\mathbf{X}-M)V^{-1}] \\
		&=\operatorname{vec}(\mathbf{X}-M)^T\operatorname{vec}[U^{-1}(\mathbf{X}-M)V^{-1}] \\
		&=\operatorname{vec}(\mathbf{X}-M)^T[(V^{-1})^T\otimes U^{-1}]\operatorname{vec}(\mathbf{X}-M) \\
		&=\operatorname{vec}(\mathbf{X}-M)^T[(V^T)^{-1}\otimes U^{-1}]\operatorname{vec}(\mathbf{X}-M) \\
		&=\operatorname{vec}(\mathbf{X}-M)^T(V^{-1}\otimes U^{-1})\operatorname{vec}(\mathbf{X}-M) \\
		&=[\operatorname{vec}(\mathbf{X})-\operatorname{vec}(M)]^T(V\otimes U)^{-1}[\operatorname{vec}(\mathbf{X})-\operatorname{vec}(M)]
	\end{align*}
	因为$\det(V\otimes U)=(\det V)^m(\det U)^n$，所以$(\det U)^{\frac{n}{2}}(\det V)^{\frac{m}{2}}$可化作$[\det(V\otimes U)]^{\frac{1}{2}}$。\info{需要补充证明，但这里涉及到了Jordan标准形，学完再来补。}
\end{proof}
\begin{corollary}
	如果正态随机矩阵$\mathbf{X}\sim MN(M,U,V)$中的每个元素都服从标准正态分布，则$M=\mathbf{0},\;V\otimes U=I_{mn}$。
\end{corollary}
由此我们看到，$M$就是正态随机矩阵$X$的均值矩阵，仍然不明确的是$U,V$到底是什么，只能说$V\otimes U$对应着$X$被向量化后的协方差矩阵，那就先来研究一下$\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{kl})$到底对应着$V\otimes U$中的哪个元素。联想正态随机向量中两个元素的协方差在协方差矩阵中的位置，我们需要找到$\mathbf{X}_{ij}$和$\mathbf{X}_{kl}$在$\operatorname{vec}(\mathbf{X})$中的索引，注意到向量化算子$\operatorname{vec}$是按列拉直，那么$\mathbf{X}_{ij}$和$\mathbf{X}_{kl}$分别在$\operatorname{vec}(\mathbf{X})$的第$(j-1)m+i$位和第$(l-1)m+k$位，于是有：
\begin{equation*}
	\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{kl})=(V\otimes U)_{(j-1)s+i,(l-1)s+k}=V_{jl}U_{ik}
\end{equation*}\par
如果$U$是一个对角阵，那么$i\ne k$时有$U_{ik}=0$，就会导致：
\begin{equation*}
	\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{kl})=V_{jl}U_{ik}=0,\;i\ne k
\end{equation*}
这表明此时只要$X$中的元素处于不同行，它们就不相关。\par
如果$V$是一个对角阵，那么$j\ne l$时有$V_{jl}=0$，就会导致：
\begin{equation*}
	\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{kl})=V_{jl}U_{ik}=0,\;j\ne l
\end{equation*}
这表明此时只要$X$中的元素处于不同列，它们就不相关。\par
对于元素$\mathbf{X}_{ij}$，有：
\begin{equation*}
	\operatorname{Var}(\mathbf{X}_{ij})=\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{ij})=V_{jj}U_{ii}
\end{equation*}
这表明此时协方差由$V_{jj}U_{ii}$控制。\par
对于同一行的元素，有：
\begin{equation*}
	\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{il})=V_{jl}U_{ii}
\end{equation*}
这表明此时协方差由$V_{jl}$控制。\par
对于同一列的元素，有：
\begin{equation*}
	\operatorname{Cov}(\mathbf{X}_{ij},\mathbf{X}_{kj})=V_{jj}U_{ik}
\end{equation*}
这表明此时协方差由$U_{ik}$控制。
\subsubsection{线性变换定义}
\begin{definition}\label{def:MatNormal3}
	$\mathbf{X}$为$m\times n$随机矩阵。若存在矩阵$A\in M_{q\times n}(\mathbb{R}),\;B\in M_{m\times p}(K)$使得$\mathbf{X}=B\mathbf{Y}A^T+M$，其中$\mathbf{Y}$是一个$p\times q$随机矩阵，$\mathbf{Y}_{ij}\sim N(0,1)$且互相独立，$i=1,2,\dots,p,\;j=1,2,\dots,q$，$M\in M_{p\times q}(\mathbb{R})$，则称$\mathbf{X}$服从矩阵正态分布，记作$X\sim MN(M,U,V)$。其中，$U=BB^T,\;V=AA^T$。
\end{definition}
\begin{theorem}
	$\mathbf{X}$是一个$m\times n$随机矩阵，则$\mathbf{X}$满足\cref{def:MatNormal2}的充分必要条件是满足\cref{def:MatNormal3}。
\end{theorem}
\begin{proof}
	\textbf{(1)必要性：}设$\mathbf{X}$满足\cref{def:MatNormal3}，由$\mathbf{Y}$的定义可知：
	\begin{equation*}
		\operatorname{vec}(\mathbf{Y})\sim N_{pq}(\mathbf{0},I_{pq})
	\end{equation*}
	由\cref{prop:VecOperator}(1)(3)可得：
	\begin{equation*}
		\operatorname{vec}(\mathbf{X})=\operatorname{vec}(B\mathbf{Y}A^T+M)=\operatorname{vec}(B\mathbf{Y}A^T)+\operatorname{vec}(M)=(A\otimes B)\operatorname{vec}(\mathbf{Y})+\operatorname{M}
	\end{equation*}
	由\cref{prop:CovMat}(3)和\cref{prop:Kronecker}(4)(2)可得：
	\begin{gather*}
		\operatorname{E}[\operatorname{vec}(\mathbf{X})] 
		= \operatorname{E}[(A \otimes B)\operatorname{vec}(\mathbf{Y}) + \operatorname{M}] 
		= (A \otimes B)\operatorname{E}[\operatorname{vec}(\mathbf{Y})] + \operatorname{M} 
		= \operatorname{M}, \\[1ex]
		\begin{aligned}
			\operatorname{Cov}[\operatorname{vec}(\mathbf{X})] 
			&= \operatorname{Cov}[(A \otimes B)\operatorname{vec}(\mathbf{Y})] \\
			&= (A \otimes B)\operatorname{Cov}[\operatorname{vec}(\mathbf{Y})](A \otimes B)^T \\
			&= (A \otimes B)I_{pq}(A^T \otimes B^T) \\
			&= AA^T \otimes BB^T.
		\end{aligned}
	\end{gather*}
	因为$\operatorname{vec}(\mathbf{X})=(A\otimes B)\operatorname{vec}(\mathbf{Y})+\operatorname{M}$，而$\operatorname{vec}(\mathbf{Y})\sim N_{pq}(\mathbf{0},I_{pq})$，由\cref{prop:MultiNormal}(2)可知：
	\begin{equation*}
		\operatorname{vec}(\mathbf{X})\sim N(\operatorname{vec}(M),AA^T\otimes BB^T)
	\end{equation*}
	令$V=AA^T,\;U=BB^T$，则有$\operatorname{vec}(\mathbf{X})\sim N(\operatorname{vec}(M),V\otimes U)$，即$\mathbf{X}$满足\cref{def:MatNormal2}。\par
	\textbf{(2)充分性：}设$\mathbf{X}$满足\cref{def:MatNormal2}，因为$U,V\geqslant0$，所以存在$U^{\frac{1}{2}}$和$V^{\frac{1}{2}}$，令$B=U^{\frac{1}{2}},A=V^{\frac{1}{2}}$，于是$\operatorname{vec}(\mathbf{X})\sim N(\operatorname{vec}(M),V\otimes U)$可写作$\operatorname{vec}(\mathbf{X})\sim N(\operatorname{vec}(M),AA^T\otimes BB^T)$。设$\mathbf{Y}$是一个随机矩阵，其中的每一个元素都服从标准正态分布且互相独立，则$\operatorname{vec}(\mathbf{X})=(A\otimes B)\operatorname{vec}(\mathbf{Y})+\operatorname{M}$。由\cref{prop:VecOperator}(1)(3)可知：
	\begin{gather*}
		\operatorname{vec}(\mathbf{X})=\operatorname{vec}(B\mathbf{Y}A^T+M)
	\end{gather*}
	于是$\mathbf{X}=B\mathbf{Y}A^T+M$，即$\mathbf{X}$满足\cref{def:MatNormal3}。
\end{proof}
\subsection{矩阵正态分布的性质}
\begin{theorem}\label{theo:MatNormalLinearTransform}
	设$\mathbf{X}$为$m\times n$随机矩阵且服从矩阵正态分布$MN(M,U,V)$，$P\in M_{s\times m}(R),\;Q\in M_{n\times t}(R)$，则$P\mathbf{X}Q^T\sim$
\end{theorem}
\begin{proof}
	由\cref{def:MatNormal3}可知$\mathbf{X}=B\mathbf{Y}A^T+M$，于是：
	\begin{equation*}
		P\mathbf{X}Q^T=PB\mathbf{Y}A^TQ^T+PMQ^T
	\end{equation*}
	此时$PBB^TP^T=PUP^T,\;QAA^TQ^T=QVQ^T$，由\cref{def:MatNormal3}即可得到结论。
\end{proof}