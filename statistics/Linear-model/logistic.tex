\section{Logistic模型}

\begin{definition}\label{model:Logistic}
	称以下模型为\textbf{逻辑回归模型}：
	\begin{equation*}
		y_i|x_i\sim\operatorname{Bernoulli}(p_i),\quad
		\operatorname{E}(y_i|x_i)=p_i =\operatorname{P}(y_i=1|x_i) =  \frac{1}{1+\exp(-x_i^T\beta)}, \quad i=1,2,\dots,n
	\end{equation*}
	其中 $y_i$相互独立，$x_i$ 为第 $i$ 个观测的 $p\times 1$ 特征向量，$\beta$ 为 $p\times1$ 的回归系数向量。记$p = (p_1,p_2,\dots,p_n)^T,\;X=(x_1;x_2;\cdots;x_n),\;y=(\seq{y}{n})$。
\end{definition}

\subsection{参数估计}
\begin{property}
	对于\cref{model:Logistic}，有如下结论：
	\begin{enumerate}
		\item $\seq{y}{n}\in\{0,1\}^n$ 的条件概率函数为：
		\begin{equation*}
			L(\beta) = \prod_{i=1}^{n} p_i^{y_i}(1-p_i)^{1-y_i}
		\end{equation*}
		\item 模型的对数似然函数为：
		\begin{equation*}
			\ln L(\beta)=\sum_{i=1}^{n} \left[y_i\log(p_i)+(1-y_i)\log(1-p_i)\right]
		\end{equation*}
		\item 模型的对数似然函数对$\beta$的梯度为：
		\begin{equation*}
			\frac{\dif\ln L(\beta)}{\dif\beta} = X^T(y - p)
		\end{equation*}
		\item 模型的对数似然函数对$\beta$的Hesse矩阵为：
		\begin{equation*}
			\frac{\dif^2\ln L(\beta)}{\dif\beta\dif\beta^T}=-X^T\operatorname{diag}\{p_1(1-p_1),p_2(1-p_2),\dots,p_n(1-p_n)\}X
		\end{equation*}
	\end{enumerate}
\end{property}
\begin{proof}
	(1)由Bernulli分布的概率函数及$y_i$之间的独立性立即可得。\par
	(2)由(1)立即可得。\par
	(3) 对 $\ell(\beta)$ 求导：
	\[
	\frac{\dif\ln L(\beta)}{\dif \beta}
	= \sum_{i=1}^n \left[ \frac{y_i}{p_i} - \frac{1 - y_i}{1 - p_i} \right] \cdot \frac{\dif p_i}{\dif \beta}
	\]
	而：
	\[
	\frac{\dif p_i}{\dif \beta}=-[1+\exp(-x_i^T\beta)]^{-2}(-x_i)\exp(-x_i^T\beta)=p_i(1 - p_i) x_i
	\]
	代入上式得：
	\begin{align*}
		\frac{\dif\ln L(\beta)}{\dif \beta}&=\sum_{i=1}^{n}\left[\frac{y_i}{p_i}-\frac{1-y_i}{1-p_i}\right]p_i(1-p_i)x_i=\sum_{i=1}^{n}[y_i(1-p_i)-(1-y_i)p_i]x_i \\
		&=\sum_{i=1}^{n}(y_i-y_ip_i-p_i+y_ip_i)=\sum_{i=1}^n (y_i - p_i)x_i = X^T(y - p)
	\end{align*}\par
	(4)对上式再求导：
	\begin{align*}
		\frac{\dif^2 \ln L(\beta)}{\dif \beta \dif \beta^T}
		&=-\sum_{i=1}^{n}\frac{\dif p_i}{\dif\beta}x_i^T=-\sum_{i=1}^{n}p_i(1-p_i)x_ix_i^T \\
		&=-X^T\operatorname{diag}\{p_1(1-p_1),p_2(1-p_2),\dots,p_n(1-p_n)\}X\qedhere
	\end{align*}
\end{proof}

\section{矩阵的分解}

\subsection{LU分解（含主元）}
\begin{theorem}\label{theo:LU}
	设$A\in M_{n}(\mathbb{R})$为可逆矩阵，则存在一个单位下三角矩阵$L$（即$L$的对角线元素均为$1$）和一个上三角矩阵$U$，使得
	\[PA = LU.\] 
	如果约定$L$的对角线元素为$1$且按消去法每步选取第一个非零元为主元，则上述分解是唯一的。
\end{theorem}
\begin{proof}
	\textbf{(1)存在性：} 对$n$进行数学归纳证明。对于$n=1$时，结论显然成立。假设对于任意$(n-1)\times(n-1)$的可逆矩阵都存在$P,L,U$使$P A = L U$成立，下面证明对$n\times n$矩阵也成立。由于$A$可逆，$A$的第一列中必定存在非零元素，设$a_{p1}$是第一个非零元素（位于第$p$行）。通过左乘首行交换矩阵交换第$1$行和第$p$行（这对应一个置换矩阵$P_1$），可以使$A$的$(1,1)$位置成为非零的主元。记变换后的矩阵仍为$A$。接下来，对$i=2,3,\dots,n$，令$l_{i1}=\frac{a_{i1}}{a_{11}}$，并用第1行的$l_{i1}$倍消去第$i$行的第1列元素（这相当于左乘一个消去矩阵$E_{i1}(-l_{i1})$）。经过这一系列初等行变换，我们得到一个新的矩阵$A^{(1)}$：
	\[ A^{(1)} = E_{n1}(-l_{n1}) \cdots E_{21}(-l_{21}) P_1 A = 
	\begin{pmatrix}
		a_{11} & u^T \\
		\mathbf{0} & A_1
	\end{pmatrix}, \] 
	其中$A_1$是$(n-1)\times(n-1)$矩阵，$\mathbf{0}$表示$(n-1)\times 1$的零向量。由于行变换不改变矩阵的秩且$a_{11}\neq0$，可知$A_1$也是可逆的。根据归纳假设，对$A_1$存在置换矩阵$P_2$、单位下三角矩阵$L'$和上三角矩阵$U'$使$P_2 A_1 = L' U'$。构造出分块矩阵：
	\[ 
	P = \begin{pmatrix}
		1 & \mathbf{0} \\
		\mathbf{0} & P_2
	\end{pmatrix}, \qquad 
	L = \begin{pmatrix}
		1 & \mathbf{0} \\
		l & L'
	\end{pmatrix}, \qquad 
	U = \begin{pmatrix}
		a_{11} & u^T \\
		\mathbf{0} & U'
	\end{pmatrix},
	\] 
	其中$l=(l_{21},l_{31},\dots,l_{n1})^T$为先前消去过程中得到的消去因子列向量。则由上述构造和归纳假设可验证：
	\[ P A = \begin{pmatrix} 1 & \mathbf{0} \\ \mathbf{0} & P_2 \end{pmatrix}
	\begin{pmatrix} a_{11} & u^T \\ \mathbf{0} & A_1 \end{pmatrix}
	= \begin{pmatrix} a_{11} & u^T \\ \mathbf{0} & P_2 A_1 \end{pmatrix}
	= \begin{pmatrix} a_{11} & u^T \\ \mathbf{0} & L' U' \end{pmatrix}
	= \begin{pmatrix} 1 & \mathbf{0} \\ l & L' \end{pmatrix}
	\begin{pmatrix} a_{11} & u^T \\ \mathbf{0} & U' \end{pmatrix} = L U, \] 
	从而完成$PA=LU$的构造。
	
	\textbf{(2)~唯一性：} 假设还有另一组分解$PA=\tilde{L}\tilde{U}$，其中$\tilde{L}$为单位下三角矩阵、$\tilde{U}$为上三角矩阵，而且满足与$L,U$相同的主元选取规则。由于$L,\tilde{L}$都是可逆的下三角矩阵，且$U,\tilde{U}$都是可逆的上三角矩阵，我们有
	\[ L^{-1}\tilde{L} = U \tilde{U}^{-1}. \] 
	左侧为一个下三角矩阵，右侧为一个上三角矩阵，因此这个等式两侧实际上都是对角矩阵。又因为$L^{-1}\tilde{L}$和$U\tilde{U}^{-1}$的对角线元素全为$1$（所有单位下三角矩阵和单位上三角矩阵的对角线元素均为1），可知$L^{-1}\tilde{L}=I$，于是$\tilde{L}=L$且$\tilde{U}=U$。因此在约定的规范下分解是唯一的。
\end{proof}

%\begin{algorithm}[!ht]
%	\caption{LU分解的高斯消去法（部分主元）}\label{alg:LU}
%	\begin{algorithmic}[1]
%		\REQUIRE 可逆矩阵$A\in \mathbb{R}^{n\times n}$
%		\ENSURE $P, L, U$使$PA=LU$（$L$为单位下三角矩阵，$U$为上三角矩阵）
%		\STATE 初始化$P=I_n,\;L=I_n,\;U=A$。
%		\FOR{$k=1$ \TO $n-1$}
%		\STATE 在第$k$列的第$k$行及以下元素中选取绝对值最大的元素作为主元，设其所在行索引为$p$。
%		\IF{$p \neq k$} 
%		\STATE 交换$U$的第$k$行和第$p$行（同时交换$P$的第$k$行和第$p$行，交换$L$的第$k$行和第$p$行的前$k-1$列元素，以维护已计算的部分）。
%		\ENDIF
%		\FOR{$i=k+1$ \TO $n$}
%		\STATE 计算消去因子$L[i,k] = U[i,k] / U[k,k]$。
%		\FOR{$j=k$ \TO $n$}
%		\STATE $U[i,j] \leftarrow U[i,j] - L[i,k] \cdot U[k,j]$。
%		\ENDFOR
%		\ENDFOR
%		\ENDFOR
%		\RETURN $P,L,U$。
%	\end{algorithmic}
%\end{algorithm}

\begin{note}
	LU分解的高斯消去算法的数值稳定性通常通过选择主元来提升。部分主元策略（每列选最大元素）能够避免除数过小导致的舍入误差放大，大多数情况下是数值后向稳定的。尽管存在构造的反例使误差增长因子达到$2^{n-1}$，但在实际应用中高斯消去配合部分主元选取可以可靠地求解线性方程组。对于一般的$n\times n$矩阵$A$，算法计算得到的$\tilde{L},\tilde{U}$满足$(L+\Delta L)(U+\Delta U) = A$，其中相对误差$\|\Delta A\|/\|A\|$通常在$\mathcal{O}(n\epsilon)$级别（$\epsilon$为机器精度），如果不存在异常的主元增长则误差很小。
\end{note}

\begin{proposition}\label{prop:LU-det}
	设$PA=LU$是$A$的LU分解，其中$P$为置换矩阵，$L$为单位下三角矩阵，$U$为上三角矩阵，则$\det(A) = \det(P)\prod_{i=1}^n u_{ii}$。特别地，由于置换矩阵$\det(P)=\pm1$且$L$的对角线全为$1$，矩阵$A$的行列式等于$U$对角线元素的乘积（当$A$不可逆时，上述乘积为$0$）。
\end{proposition}
\begin{proof}
	因为$\det(P)\neq0$且$\det(L)=1$，对$PA=LU$两侧取行列式，得到$\det(P)\det(A)=\det(L)\det(U)$，即$\det(P)\det(A)=\det(U)$。由于$U$是上三角矩阵，其行列式为对角线元素之积$\prod_{i=1}^n u_{ii}$。因此$\det(A) = \det(P)^{-1}\det(U) = \det(P)\prod_{i=1}^n u_{ii}$（因为$\det(P)=\pm1$是自身的逆）。
\end{proof}

\begin{note}
	LU分解可用于高效地求解线性方程组和计算矩阵的逆等问题。对于方程$Ax=b$，先计算$PA=LU$，然后解$Ly=Pb$（前代入求$y$），再解$Ux=y$（回代求$x$），即可在$\mathcal{O}(n^2)$时间内得到解$x$。类似地，要计算$A^{-1}$，只需将单位矩阵$I$的列依次作为右端项$b$求解$Ax=e_i$，即可构造出$A^{-1}$。这些操作利用了$L,U$的三角结构，使得计算复杂度远小于直接求解或计算伴随矩阵。
\end{note}

\subsection{Cholesky分解（及$LDL^T$分解）}
\begin{theorem}\label{theo:Cholesky}
	设$A\in M_{n}(\mathbb{R})$是对称正定矩阵（即$\forall x\neq 0,\;x^T A x>0$），则存在唯一一个下三角矩阵$L$使得$A=LL^T$，其中$L$的对角线元素均为正数。该分解称为$A$的Cholesky分解。
\end{theorem}
\begin{proof}
	\textbf{存在性：} 同样采用数学归纳法。对于$n=1$时，$A=[a_{11}]$正定意味着$a_{11}>0$，则取$L=[\sqrt{a_{11}}]$即可。假设对任意$(n-1)\times(n-1)$的对称正定矩阵都存在Cholesky分解，考虑$n\times n$情形。将$A$分块：
	\[ A = \begin{pmatrix} 
		a_{11} & r^T \\[6pt]
		r & A_1 
	\end{pmatrix},\] 
	其中$a_{11}>0$（因为$A$正定）且$r\in \mathbb{R}^{n-1}$为$A$第一列除去$a_{11}$后的部分，$A_1$为$(n-1)\times(n-1)$的子矩阵。令$l_{11}=\sqrt{a_{11}}$，并定义$c=\frac{1}{l_{11}}\,r$为长度为$n-1$的列向量。构造
	\[ L = \begin{pmatrix}
		l_{11} & \mathbf{0}^T \\
		c & L_1
	\end{pmatrix}, \] 
	其中$L_1$是递归假设下$A_1 - cc^T$的Cholesky分解矩阵。下面证明$A_1-cc^T$也是对称正定矩阵，从而$L_1$存在。对任意非零向量$y\in \mathbb{R}^{n-1}$，考虑扩充向量$\tilde{x}=\begin{pmatrix}-\frac{y^T r}{a_{11}} \\[3pt] y\end{pmatrix}\in \mathbb{R}^n$，由$A$正定知$\tilde{x}^T A\, \tilde{x}>0$。展开该二次型：
	\[
	\tilde{x}^T A\,\tilde{x} = \begin{pmatrix} -\frac{y^T r}{a_{11}} & y^T \end{pmatrix} 
	\begin{pmatrix} a_{11} & r^T \\ r & A_1 \end{pmatrix} 
	\begin{pmatrix} -\frac{y^T r}{a_{11}} \\[4pt] y \end{pmatrix}
	= -2\frac{y^T r}{a_{11}}y^T r + y^T (A_1)y + \frac{(y^T r)^2}{a_{11}}. 
	\] 
	整理得$y^T (A_1 - \frac{1}{a_{11}} r\,r^T)y = \tilde{x}^T A\,\tilde{x} > 0$。注意$\frac{1}{a_{11}}r\,r^T = cc^T$，故对任意$y\neq 0$有$y^T(A_1 - cc^T)y>0$，说明$A_1-cc^T$是$(n-1)\times(n-1)$的对称正定矩阵。根据归纳假设，$A_1-cc^T$存在Cholesky分解$A_1-cc^T = L_1 L_1^T$。由此$L$得以构造完成，并满足：
	\[ LL^T = \begin{pmatrix} l_{11} & \mathbf{0}^T \\ c & L_1 \end{pmatrix}
	\begin{pmatrix} l_{11} & c^T \\ \mathbf{0} & L_1^T \end{pmatrix}
	= \begin{pmatrix} l_{11}^2 & l_{11} c^T \\ l_{11} c & cc^T + L_1 L_1^T \end{pmatrix}
	= \begin{pmatrix} a_{11} & r^T \\ r & cc^T + (A_1 - cc^T) \end{pmatrix}
	= \begin{pmatrix} a_{11} & r^T \\ r & A_1 \end{pmatrix} = A.
	\]
	
	\textbf{唯一性：} 假设$A=L L^T=\tilde{L}\tilde{L}^T$是两种Cholesky分解，其中$L,\tilde{L}$都是下三角且对角线元素为正。考虑$M=L^{-1}\tilde{L}$，则
	\[ M M^T = L^{-1} \tilde{L}\,\tilde{L}^T (L^{-1})^T = L^{-1} A (L^{-1})^T = I. \] 
	这说明$M$是正交矩阵。但$M$还是下三角矩阵且对角线元素为正实数，下三角正交矩阵只能是恒等矩阵（因为正交矩阵满足$M^T M=I$，而$M$下三角则$M$必须为对角线全$1$的矩阵）。因此$M=I$，即$\tilde{L}=L$。
\end{proof}

%\begin{algorithm}[!ht]
%	\caption{Cholesky分解算法}\label{alg:Cholesky}
%	\begin{algorithmic}[1]
%		\REQUIRE 对称正定矩阵$A\in \mathbb{R}^{n\times n}$
%		\ENSURE 下三角矩阵$L$使$A = LL^T$
%		\FOR{$k=1$ \TO $n$}
%		\STATE $L[k,k] = \sqrt{\,A[k,k] - \sum_{j=1}^{k-1} L[k,j]^2\,}$。
%		\FOR{$i=k+1$ \TO $n$}
%		\STATE $L[i,k] = \frac{1}{L[k,k]}\Big(A[i,k] - \sum_{j=1}^{k-1} L[i,j]\,L[k,j]\Big)$。
%		\ENDFOR
%		\ENDFOR
%		\RETURN $L$。
%	\end{algorithmic}
%\end{algorithm}

\begin{note}
	Cholesky分解的数值计算非常稳定。如果$A$正定，算法每一步都从当前子矩阵的对角元开方，这些对角元始终为正且不会受到消去误差的影响。实际计算中，即使考虑舍入误差，所得$\tilde{L}$满足$(A+\Delta A) = \tilde{L}\tilde{L}^T$，其中$\|\Delta A\|$相对于$\|A\|$的大小在机器误差阶上。与直接求$A^{-1}$或者使用$A^TA$求解正规方程相比，Cholesky分解避免了误差的放大，是求解对称正定线性系统的首选方法。
\end{note}

\begin{corollary}[主子式判定准则]\label{cor:Sylvester}
	对称矩阵$A$是正定矩阵的充要条件是$A$的所有顺序主子式（即左上角$k\times k$子式，$k=1,2,\dots,n$）均为正数。
\end{corollary}
\begin{proof}
	\textbf{正定$\Rightarrow$主子式全正：} 若$A=LL^T$是$A$的Cholesky分解，其中$L$对角线元素$l_{ii}>0$。则对于每个$k$，$A$的前$k$阶主子矩阵可表示为$L_k L_k^T$，其中$L_k$是$L$取前$k$行、前$k$列的主要部分。因此该$k$阶主子矩阵的行列式$\det(A_k) = \det(L_k)^2 = \prod_{i=1}^k l_{ii}^2>0$。
	
	\textbf{主子式全正$\Rightarrow$正定：} 此方向可通过反证证明。若$A$不是正定的，则存在非零$x$使$x^T A x \le 0$。令$x=(x_1,\dots,x_n)^T$，设$x_m$是最后一个非零分量（$m$存在且$\le n$）。考虑$A$的前$m$行$m$列的主子矩阵$A_m$。因为$x_m\neq0$且$x_i=0$对$i>m$，有$x^T A x = x_{1:m}^T A_m x_{1:m} \le 0$，其中$x_{1:m}$是$x$的前$m$维截断向量。这表明$A_m$不是正定的，从而存在$A_m$的顺序主子式不满足正值（根据主子式判定正定的充分条件部分）。这与假设$A$所有顺序主子式均正相矛盾。因此$A$必为正定矩阵。
\end{proof}

\begin{note}
	对于任意实对称矩阵$A$，都可以通过有限步初等变换将其分解为$A=P^T L D L^T P$，其中$P$是置换矩阵，$L$是单位下三角矩阵，$D$是对角块矩阵（其对角元可能出现负数或$2\times 2$实块）。这称为$A$的$LDL^T$分解。当$A$正定时，可取$P=I$且$D$为正对角矩阵即退化为Cholesky分解。一般情况下，$D$对角元的正负号个数与$A$特征值正负个数相对应，这就是矩阵的惯性定理（Sylvester惯性定理）：无论经过怎样的相似变换，$A$正负特征值的数量不变。在惯性定理的意义下，$LDL^T$分解提供了一种计算矩阵正负惯性的途径。
\end{note}

\subsection{QR分解}
\begin{theorem}
	设$A\in M_{n}(\mathbb{R})$为可逆矩阵，则存在一个正交矩阵$Q$和一个上三角矩阵$R$使得 
	\[ A = Q R. \] 
	当约定$R$的对角线元素皆为正值时，上述分解是唯一的。这种分解称为矩阵$A$的QR分解。
\end{theorem}
\begin{proof}
	\textbf{(1)~存在性：}我们介绍三种构造正交矩阵$Q$的方法来证明QR分解的存在性。\par
	\textbf{Gram-Schmidt正交化：} 将$A$的列向量依次进行正交归一化处理。设$A=[a_1, a_2, \dots, a_n]$，其中$a_j$表示$A$的第$j$列。因为$A$可逆，各列向量线性无关。令$q_1=\frac{a_1}{\|a_1\|}$作为$Q$的第一列，取$r_{11}=\|a_1\|$。对于$j=2$到$n$，令$q_j'$为$a_j$在前$j-1$个已正交列的正交补部分：计算$r_{ij}=q_i^T a_j$对于$i=1,2,\dots,j-1$，并令 
	\[ q_j' = a_j - \sum_{i=1}^{j-1} r_{ij}\,q_i. \] 
	由于$\{a_1,\dots,a_{j-1}\}$线性无关可保证$q_j'\neq 0$。然后令$r_{jj}=\|q_j'\|$并归一化$q_j = q_j'/r_{jj}$作为$Q$的第$j$列。如此递推下去，我们得到$Q=[q_1,\dots,q_n]$是一个正交矩阵，而对应的$R=[r_{ij}]$是上三角矩阵，其中$r_{ij}=q_i^T a_j$（当$i\le j$）或$r_{ij}=0$（当$i>j$）。由上述构造可以验证$A=QR$。这种方法即为Gram-Schmidt正交化算法。\par
	\textbf{Givens旋转：} Givens变换通过二维平面内的旋转将矩阵中某个元素消去为零。对于$A$的任意一个非零的下三角元素$a_{ij}$（$i>j$），存在一个Givens旋转矩阵$G_{ij}$（是一个单位正交矩阵，只在第$i$和$j$行（列）的$2\times 2$子块为$\begin{pmatrix}c & s\\ -s & c\end{pmatrix}$，其它为单位阵）能够将$A$左乘后把该元素消去，即$G_{ij} A$的$(i,j)$位置变为$0$。通过顺次选取合适的$(i,j)$对并左乘相应的Givens矩阵，可以依次将$A$下三角区域的元素逐个消去为零。当所有$i>j$处的元素都被消去后，我们得到$R$是上三角矩阵，同时左乘的Givens矩阵累乘形成了一个正交矩阵$Q$，满足$Q A = R$，即得到$A=Q^T R$（因为Givens旋转是对称正交的）。取$Q^T$代替原来的$Q$，同样可以表示出$A=Q R$形式。\par 
	\textbf{Householder变换：} Householder变换使用反射矩阵一次性将一列中若干项同时消为零。首先，对于$A$的第一列$a_1$，构造第一个Householder矩阵$H_1=I - 2uu^T$，其中$u$为合适的单位向量，使得$H_1 a_1$仅在第1行有非零元素（即$H_1 a_1 = [\alpha,0,0,\dots,0]^T$）。将$H_1$作用于$A$的左侧，可以将$A$的第一列除首元素外的元素全部反射到零，得到$H_1A=\begin{pmatrix}\alpha & * \\ \mathbf{0} & A_1\end{pmatrix}$，其中$A_1$是剩余的$(n-1)\times(n-1)$子块矩阵，$\alpha\neq0$。然后对$A_1$重复上述过程：存在第二个Householder矩阵$H_2'$使得$H_2' A_1$的第一列仅第一行非零。将$H_2'$扩大嵌入为$n\times n$矩阵$H_2=\begin{pmatrix}1 & \mathbf{0}\\ \mathbf{0} & H_2'\end{pmatrix}$，它只作用于$A$的后$n-1$行。于是$H_2H_1 A$使$A$的前两列除了主对角元外均为零。如此继续构造$H_3,H_4,\dots,H_n$，最终得到$H_n \cdots H_2 H_1 A = R$为上三角矩阵。令$Q = (H_n \cdots H_2 H_1)^T$（注意Householder矩阵也是对称的，即$H_i^T = H_i$），则$Q$是正交矩阵且满足$Q A = R$，即$A=Q^T R$，同样取$Q^T$重新记作$Q$即可得到$A=QR$。以上过程证明了QR分解的存在性。
	\par
	\textbf{(2)~唯一性：} 如果$A=Q R = Q' R'$是两种QR分解，其中$Q,Q'$都是正交矩阵，$R,R'$都是上三角矩阵。由于$Q^{-1} = Q^T$，比较得$Q'^T Q = R' R^{-1}$。左边是正交矩阵，右边是上三角矩阵，因此$Q'^T Q$必为对角矩阵。也就是说，存在一个对角矩阵$D=(\pm1,\pm1,\dots,\pm1)$使$Q' = QD$和$R' = D^{-1} R$。当我们规定$R$的对角元素均为正值时，上述$D$只能取单位矩阵$I$，因此$Q'=Q,\;R'=R$，唯一性得证。
\end{proof}

\begin{note}
	通过以上证明可见，QR分解只有在对$R$的对角线作出适当正符号约定时才唯一。例如，如果$A=Q R$是一个QR分解，那么令$D=\{\,\frac{r_{11}}{|r_{11}|},\frac{r_{22}}{|r_{22}|},\dots,\frac{r_{nn}}{|r_{nn}|}\}$，可以发现$Q'=QD$仍为正交矩阵，而$R'=D^{-1}R$成为对角元非负的上三角矩阵，且$A=Q'R'$。这种$R'$称为$A$的标准形QR分解，在此规范下$Q,R$由$A$唯一确定。
\end{note}

%\begin{algorithm}[!ht]
%	\caption{Gram-Schmidt正交化QR分解算法}\label{alg:GS-QR}
%	\begin{algorithmic}[1]
%		\REQUIRE 满秩矩阵$A=[a_1,\dots,a_n]\in \mathbb{R}^{m\times n}$（假设$\rank(A)=n$）
%		\ENSURE 正交矩阵$Q\in \mathbb{R}^{m\times n}$，上三角矩阵$R\in \mathbb{R}^{n\times n}$，使$A=QR$
%		\FOR{$j=1$ \TO $n$}
%		\STATE $v = a_j$。\quad // 当前待正交化的向量
%		\FOR{$i=1$ \TO $j-1$}
%		\STATE $R[i,j] = q_i^T v$。 \quad // 计算$v$在已得到的$q_i$方向上的分量
%		\STATE $v \leftarrow v - R[i,j]\; q_i$。 \quad // 从$v$中减去在$q_i$方向的投影
%		\ENDFOR
%		\STATE $R[j,j] = \|\,v\|$。 \quad // 计算正交化后的向量模长
%		\STATE $q_j = v / R[j,j]$。\quad // 归一化得到$Q$的第$j$列
%		\ENDFOR 
%		\RETURN $Q=[q_1,\dots,q_n],\;R=[R[i,j]]$。
%	\end{algorithmic}
%\end{algorithm}

%\begin{algorithm}[!ht]
%	\caption{Householder变换QR分解算法}\label{alg:HH-QR}
%	\begin{algorithmic}[1]
%		\REQUIRE $A\in \mathbb{R}^{m\times n}$（假设$\rank(A)=n\le m$）
%		\ENSURE 正交矩阵$Q\in \mathbb{R}^{m\times m}$，上三角矩阵$R\in \mathbb{R}^{m\times n}$，使$A=QR$
%		\STATE 初始化$Q = I_m,\;R = A$。
%		\FOR{$k=1$ \TO $n$}
%		\STATE 提取$R$的第$k$列下面部分的向量：$x = R[k:m,\;k]$。
%		\STATE 计算$\alpha = -\sign(x[1])\,\|x\|$。
%		\STATE 构造Householder向量：$u = \frac{1}{\sqrt{2\|x\|(\|x\| - x[1])}}(x - \alpha\, e_1)$，其中$e_1=(1,0,\dots,0)^T$为适当维度的单位向量。
%		\STATE 计算Householder矩阵：$H = I_{m-k+1} - 2\,u\,u^T$。
%		\STATE 将$H$嵌入扩展为$\hat{H} = \begin{pmatrix} I_{k-1} & \mathbf{0} \\ \mathbf{0} & H \end{pmatrix} \in \mathbb{R}^{m\times m}$。
%		\STATE $R \leftarrow \hat{H}\,R$。\quad // $H$作用于$R$消去第$k$列的第$k+1$至$m$行元素
%		\STATE $Q \leftarrow Q\,\hat{H}^T$。\quad // 将变换累乘到$Q$（或等价地右乘$Q$以更新）
%		\ENDFOR
%		\RETURN $Q,\;R$。\quad // 输出使$A=QR$的$Q$（$m\times m$正交）和$R$（$m\times n$上三角）
%	\end{algorithmic}
%\end{algorithm}

\begin{note}
	在QR分解的计算中，不同的方法有不同的数值稳定性。Householder变换法和Givens旋转法都具有良好的数值稳定性，通常是后向稳定的，意味着求得的$\tilde{Q},\tilde{R}$满足$\tilde{Q}\tilde{R} = A + E$且$\|E\|$相对$\|A\|$很小。在实际实现中，Householder法由于效率和稳定性的平衡，被广泛采用。相比之下，经典Gram-Schmidt正交化在处理病态矩阵（列向量接近线性相关）时容易因舍入误差导致正交性丧失。改进的Gram-Schmidt算法通过在减去投影后重新正交一次来缓解这一问题，但其稳定性仍不及Householder法。一般而言，当矩阵的条件数较大时，推荐使用Householder或Givens方法来计算QR分解，以确保得到高精度的正交基。
\end{note}

\begin{proposition}
	如果$A=QR$是$m\times n$矩阵（$\operatorname{rank}(A)=n$）的QR分解，其中$Q=[q_1,\dots,q_m]\in \mathbb{R}^{m\times m}$是正交矩阵（取列满空间的延拓形式），$R=\begin{pmatrix}R_{11}\\ \mathbf{0}\end{pmatrix}\in \mathbb{R}^{m\times n}$，其中$R_{11}\in \mathbb{R}^{n\times n}$是可逆的上三角矩阵，那么对任意向量$b\in \mathbb{R}^m$，最小二乘问题$\min_{x\in \mathbb{R}^n}\|Ax-b\|_2$的解为 
	\[x^* = R_{11}^{-1}(Q^T b)_{1:n},\] 
	其中$(Q^T b)_{1:n}$表示向量$Q^T b$的前$n$个分量。换言之，$x^* = R^{-1} Q^T b$。
\end{proposition}
\begin{proof}
	由于$Q$正交，$\|Ax-b\|_2 = \|Q^T(Ax-b)\|_2 = \|Q^T Ax - Q^T b\|_2 = \|Rx - Q^T b\|_2$。记$Q^T b = \begin{pmatrix} c_1 \\ c_2 \end{pmatrix}$，其中$c_1\in \mathbb{R}^n$由前$n$个分量组成，$c_2\in \mathbb{R}^{m-n}$由剩余分量组成，则$\|Rx-Q^T b\|_2^2 = \|R_{11}x - c_1\|_2^2 + \|c_2\|_2^2$。对给定$b$，$\|c_2\|_2^2$是常数。为了最小化上述范数，必须令$R_{11}x = c_1$，因为$R_{11}$可逆，此方程有唯一解$x = R_{11}^{-1} c_1$。此时残差范数为$\|c_2\|_2$达到最小，故$x^* = R_{11}^{-1} c_1$即为最小二乘解。
\end{proof}

\begin{note}
	QR分解的一个重要应用是用于计算矩阵的特征值，即著名的QR算法。具体做法是不断将矩阵分解并迭代：给定$A^{(0)}=A$，计算$A^{(0)}=Q_1 R_1$，然后令$A^{(1)}=R_1 Q_1$；再对$A^{(1)}$进行QR分解$A^{(1)}=Q_2 R_2$，令$A^{(2)}=R_2 Q_2$，以此类推。适当的位移策略可加速收敛。当迭代收敛时，$A^{(k)}$趋近于一个上三角矩阵$T$，其中$T$的对角元即为初始矩阵$A$的特征值。这种算法在数值上表现出极好的稳定性，是通用计算特征值的高效方法。
\end{note}

\subsection{SVD分解}
\begin{theorem}\label{theo:SVD}
	设$A\in M_{m\times n}(\mathbb{R})$，$\operatorname{rank}(A)=r$，则存在一个$U\in M_{m}(\mathbb{R})$和一个$V\in M_{n}(\mathbb{R})$，它们都是正交矩阵，使得：
	\[ 
	A = U\,\Sigma\,V^T,
	\] 
	其中$\Sigma\in M_{m\times n}(\mathbb{R})$，其主对角线上由$r$个正数$\sigma_1,\sigma_2,\dots,\sigma_r$组成（其余元素为$0$），并且$\sigma_i^2$是矩阵$A^T A$的$r$个正特征值。
\end{theorem}
\begin{proof}
	考虑对称矩阵$A^T A\in M_{n}(\mathbb{R})$。由于$A^T A$是半正定的，对任意非零向量$y$都有$y^T (A^T A) y = \|Ay\|_2^2 \ge 0$。并且$\operatorname{rank}(A^T A) = \operatorname{rank}(A) = r$（显然零空间$(A^T A)=(A)$）。因此$A^T A$存在恰有$r$个正特征值。设这些正特征值为$\lambda_1^2 \ge \lambda_2^2 \ge \cdots \ge \lambda_r^2>0$，其对应单位特征向量为$v_1,\dots,v_r\in \mathbb{R}^n$。将$A^T A$剩余的$n-r$个零特征值的特征向量记作$v_{r+1},\dots,v_n$，可以选取它们两两正交并与前$r$个特征向量正交，从而得到一组完整的正交基$\{v_1,\dots,v_n\}$。将这些列向量排列构成正交矩阵$V=[v_1,\dots,v_n]\in \mathbb{R}^{n\times n}$。于是
	\[ V^T (A^T A) V = (\lambda_1^2,\dots,\lambda_r^2,0,\dots,0).\] 
	现在令$\sigma_i = \lambda_i\ (>0)$对$i=1,\dots,r$，并构造对角矩阵$\Sigma \in M_{m\times n}$，使其对角线前$r$项$\Sigma_{ii}=\sigma_i$，其余元素为0。对于每一个$i=1,\dots,r$，由于$A^T A\,v_i = \lambda_i^2 v_i$，并且$\lambda_i=\sigma_i$，我们有$A v_i$是长度为$\sigma_i$的向量。定义$u_i = \frac{1}{\sigma_i} A v_i$，则$u_i$是单位向量，并且对于$i\neq j$，有
	\[ u_i^T u_j = \frac{1}{\sigma_i \sigma_j} v_i^T A^T A\, v_j = \frac{1}{\sigma_i \sigma_j} v_i^T (\lambda_j^2 v_j) = 0, \] 
	即$u_i$与$u_j$正交。另外，当$i>r$时，$\sigma_i=0$且$v_i$是$A^T A$的零特征向量，可以任意选择$u_i$为$\mathbb{R}^m$中与$u_1,\dots,u_r$正交的单位向量来完成基。将$u_1,\dots,u_m$列成矩阵$U=[u_1,\dots,u_m]\in \mathbb{R}^{m\times m}$，因为这些$u_i$两两正交归一，$U$是正交矩阵。由上述构造，我们有对于$1\le i\le r$，
	\[ A v_i = \sigma_i u_i, \] 
	以及对于$r<i\le n$，$A v_i = 0 = \sigma_i u_i$也成立（因为$\sigma_i=0$）。将这些关系汇总，可以写成矩阵形式：
	\[ A [v_1,\dots,v_n] = [u_1,\dots,u_m] \begin{pmatrix}
		\sigma_1 & & & \mathbf{0}\\
		& \sigma_2 & & \\
		& & \ddots & \\
		\mathbf{0} & & & \sigma_n
	\end{pmatrix}, \] 
	即 
	\[ A V = U \Sigma. \] 
	两边同时右乘$V^T$，并注意到$V^T=V^{-1}$，得到$A = U\,\Sigma\,V^T$，这正是所要求的分解形式。
\end{proof}

\begin{definition}
	设$A\in M_{m\times n}(\mathbb{R})$，$\operatorname{rank}(A)=r$，记定理中$\Sigma$对角线上$\sigma_1,\sigma_2,\dots,\sigma_r$为$A$的\gls{SingularValue}。这些值按约定通常排序为$\sigma_1\ge \sigma_2\ge \cdots \ge \sigma_r>0$。当允许重复计数时，$\sigma_{r+1}=\cdots=\sigma_{\min\{m,n\}}=0$也被称为$A$的奇异值。
\end{definition}

由于$A$的奇异值是$A^T A$的特征值开方而得，奇异值具有良好的性质：它们总是非负实数，并且对扰动不太敏感。特别地，矩阵$A$的2-范数$\|A\|_2=\sigma_1$，Frobenius范数$\|A\|_F=\sqrt{\sum_{i=1}^r \sigma_i^2}$，奇异值越小的方向越不稳定但对$A$贡献越小。

%\begin{algorithm}[!ht]
%	\caption{计算矩阵的奇异值分解}\label{alg:ComputeSVD}
%	\begin{algorithmic}[1]
%		\REQUIRE $A\in \mathbb{R}^{m\times n}$
%		\ENSURE $U,\Sigma,V$，其中$U\in \mathbb{R}^{m\times m}$、$V\in \mathbb{R}^{n\times n}$为正交矩阵，$\Sigma\in \mathbb{R}^{m\times n}$为奇异值对角矩阵，使$A = U\,\Sigma\,V^T$
%		\STATE 计算$B = A^T A\in \mathbb{R}^{n\times n}$（对称半正定矩阵）。
%		\STATE 计算$B$的特征分解：$B\,=\,V\,\Lambda\,V^T$，其中$\Lambda=\diag(\lambda_1^2,\lambda_2^2,\dots,\lambda_n^2)$且$\lambda_1\ge \lambda_2\ge\cdots\ge\lambda_n\ge 0$。
%		\STATE 令$\sigma_i = \lambda_i$（当$\lambda_i\neq0$）并将$\sigma_i$依降序排列构成$\Sigma$矩阵（若$m>n$则在$\Sigma$中补足$m-n$行零）。
%		\STATE 计算$U$的前$n$列：对每个$1\le i\le n$，令$u_i = \begin{cases}
%			\frac{1}{\sigma_i} A v_i, & \sigma_i > 0;\\
%			\text{任取一个单位向量与前$i-1$个正交}, & \sigma_i = 0,
%		\end{cases}$ 并正则化为单位向量。
%		\STATE 将剩余的$m-n$列$u_{n+1},\dots,u_m$补为任意标准正交向量使$U$成为$m\times m$的正交矩阵。
%		\RETURN $U,\Sigma,V$。
%	\end{algorithmic}
%\end{algorithm}

\begin{note}
	上述直接利用$A^T A$的特征分解来构造SVD的方法在实际数值计算中并不理想，因为若$A$的条件数很大，$A^T A$的特征值会出现严重的舍入误差。更为有效和稳定的SVD算法通常不显式形成$A^T A$，而是先通过Householder变换将$A$化为双对角形矩阵，再对该小型矩阵应用迭代方法（如带移位的QR算法或Divide-and-Conquer方法）计算奇异值和奇异向量。这些算法能够在保持数值稳定的同时高效地计算SVD。在实际应用中，SVD计算出的奇异值精度极高，即使矩阵$A$的谱条件数很大，最大的和最小的奇异值也能可靠地辨别出来。不过，当$A$存在成对接近的奇异值时，对应的奇异向量可能不稳定（小扰动会引起奇异子空间的较大旋转），这时只能信赖于奇异向量所张成的子空间而非单个向量方向。
\end{note}

%\begin{proposition}[Eckart-Young定理]
%	设矩阵$A\in \mathbb{R}^{m\times n}$的奇异值按降序为$\sigma_1 \ge \sigma_2 \ge \cdots \ge \sigma_{\min\{m,n\}}$。对任意$k<\rank(A)$，使$X$为秩至多$k$的矩阵时，$A$与$X$之差的Frobenius范数的最小可能值为
%	\[ \min_{\rank(X)\le k} \|A - X\|_F = \sqrt{\sigma_{k+1}^2 + \sigma_{k+2}^2 + \cdots + \sigma_r^2}, \] 
%	其中$r=\rank(A)$。当取$X = \sum_{i=1}^k \sigma_i\, u_i v_i^T$（即$A$的前$k$个奇异值和奇异向量重构的秩$k$矩阵）时，上述最小值取得。
%	此外，在2-范数意义下$\min_{\rank(X)\le k}\|A-X\|_2 = \sigma_{k+1}$，由同一个$X$取得。
%\end{proposition}
%\begin{proof}
%	令$A=U \Sigma V^T$为$A$的SVD，其中$\Sigma=\diag(\sigma_1,\dots,\sigma_r,0,\dots,0)$，$U=[u_1,\dots,u_m]$，$V=[v_1,\dots,v_n]$。任意$\rank(X)\le k$的矩阵$X$可以表示为$X = U Y V^T$，其中$Y$是只含前$k$个非零奇异值的矩阵（其秩不超过$k$）。则
%	\[ \|A - X\|_F^2 = \|U\Sigma V^T - U Y V^T\|_F^2 = \|\Sigma - Y\|_F^2 = \sum_{i=1}^{\min\{m,n\}} (\sigma_i - Y_{ii})^2. \] 
%	由于$Y$至多只有$k$个非零对角元，而$\Sigma$有$r>k$个，对第$k+1,\dots,r$这些指标，$\sigma_i - Y_{ii} = \sigma_i - 0 = \sigma_i$。因此
%	\[ \|A - X\|_F^2 \ge \sum_{i=k+1}^r \sigma_i^2, \] 
%	且等号当且仅当取$Y_{ii}=\sigma_i$对于$i\le k$，而$Y_{ii}=0$对于$i>k$时成立，也就是$Y$为$\diag(\sigma_1,\dots,\sigma_k,0,\dots,0)$。此时$X=U Y V^T = \sum_{i=1}^k \sigma_i\,u_i v_i^T$，达到下界。
%	对于2-范数，由于$\|A-X\|_2 = \max_i |\sigma_i - Y_{ii}|$，类似地，由于$Y$至多$k$个非零元素，至少有$\sigma_{k+1}$未被匹配消除，因此$\|A-X\|_2 \ge \sigma_{k+1}$，只有当$Y_{ii}=\sigma_i$（$i=1,\dots,k$）时取等并得到$\|A-X\|_2 = \sigma_{k+1}$。
%\end{proof}
%
%\begin{note}
%	奇异值分解还有重要的应用于求解广义逆和最小二乘问题。当$A=U\Sigma V^T$为SVD时，定义$A$的Moore-Penrose伪逆$A^+$为 
%	\[ A^+ = V\,\Sigma^+\,U^T, \] 
%	其中$\Sigma^+$是在$\Sigma$非零对角元素处取倒数、其它处保持零所得到的$n\times m$矩阵。有了$A^+$，可以在$A$不可逆或非方阵时求解$Ax=b$的最小二乘解和最小范数解。事实上，一般地$A^+ b$给出$Ax=b$的最小二乘解（总是存在），并且当方程组有解时它也是最小范数解。可以验证：$A^+ A$是$\mathbb{R}^n$到自身的正交投影（映射到$\col(V)$子空间），而$A A^+$是$\mathbb{R}^m$上的正交投影（映射到$\col(U)$）。此外，当$A$退化时，$A^+$相当于对$\Sigma$中的零奇异值取倒数，会得到无穷大的形式，但由于实际实现中只对非零奇异值取倒数并将小奇异值视作0处理，SVD能帮助我们稳健地识别数值秩，从而构造数值伪逆以解决病态问题。
%\end{note}
%
%\subsection{极分解}
%\begin{theorem}\label{theo:Polar}
%	设$A\in M_{n}(\mathbb{R})$为可逆矩阵，则存在唯一的正交矩阵$Q$和对称正定矩阵$H$使得 
%	\[ A = Q\,H. \] 
%	如果$A$不可逆，上述分解亦存在（其中$H$仅半正定，此时$Q$在$\nul(A)$对应子空间上的取值不唯一）。该分解称为$A$的极分解。
%\end{theorem}
%\begin{proof}
%	$A$可逆时，令$H=\sqrt{A^T A}$表示$A^T A$的唯一正定平方根矩阵，再定义$Q = A\,H^{-1}$。下面验证$Q$与$H$满足要求：首先，$H$是对称正定矩阵且$Q = A H^{-1}$由定义成立，从而$A=QH$。接着，由于 
%	\[ Q^T Q = (A H^{-1})^T (A H^{-1}) = H^{-1} (A^T A) H^{-1} = H^{-1} H^2 H^{-1} = I, \] 
%	可知$Q^T Q = I$，即$Q$是正交矩阵。最后说明这种表示是唯一的：若还有$A = Q' H'$是另一种正交-正定分解，则
%	\[ Q'{}^T Q = H' H^{-1}. \] 
%	左边是正交矩阵，右边是正定矩阵。只有单位矩阵同时满足既是正交又是正定的性质，因此$Q'{}^T Q = I$，从而$Q'=Q$且$H'=H$。对于$A$不可逆的情况，$H=\sqrt{A^T A}$仍然存在但不可逆（半正定），此时定义$Q=A H^{\dagger}$，其中$H^{\dagger}$是$H$的广义逆（在$H$的零特征子空间上任取$Q$的取值使之成为正交矩阵）。这样构造的$Q$仍满足$Q^T Q = I$且$A=QH$。但是在$A$不可逆时，如果$A$在某个方向上奇异，那么$Q$在那个方向上的取值并不唯一。综上，极分解总是存在，且在$A$可逆时具有唯一性。
%\end{proof}
%
%极分解将任意矩阵分解为一个“正交部分”和一个“对称正定部分”。从SVD可以很容易地构造出极分解：对$A$作SVD得到$A=U\Sigma V^T$，则令$Q = U V^T$，$H = V \Sigma V^T$，此时$Q$为正交矩阵、$H$为对称正定矩阵，且$A = (U V^T)(V \Sigma V^T) = U \Sigma V^T$，恰好复原$A$。值得注意的是，当$A$可逆时，$H = \sqrt{A^T A}$可直接用于表示$Q = A (A^T A)^{-1/2}$。
%
%\begin{note}
%	极分解在数值代数和应用中有诸多作用。例如，对于给定矩阵$A$，它的正交因子$Q$实际上是与$A$“最近”的正交矩阵，可证明对于任何正交矩阵$X$，
%	\[ \|A - Q\|_F = \min_{X^T X = I} \|A - X\|_F, \] 
%	其中$\|\cdot\|_F$为Frobenius范数。这一性质在计算最近正交矩阵（例如在数值优化中将一个矩阵投影到正交群上）时非常有用。另外，在计算矩阵函数时，极分解也提供了有效途径，例如矩阵的$\sign$函数可以通过$A=QH$得到$\sign(A)=Q$。在力学中，极分解被用来描述连续介质的形变：任意一个可逆矩阵$A$可以视为一个旋转（正交部分$Q$）和一个拉伸（对称正定部分$H$）的复合，这就是刚体旋转与应变的分离，被广泛应用于计算机图形学和弹性力学中。
%\end{note}
%
%\subsection{Schur分解与谱分解}
%\begin{theorem}[Schur分解]\label{theo:Schur}
%	设$A\in M_{n}(\mathbb{C})$，则存在一个酉矩阵（即复正交矩阵）$Q$，使得 
%	\[ Q^* A\, Q = T, \] 
%	其中$T$为上三角矩阵。并且$T$的对角元即为矩阵$A$的全部特征值。此分解称为$A$的Schur分解。
%\end{theorem}
%\begin{proof}
%	我们通过数学归纳法证明。对于$n=1$时结论平凡成立。假设对于任意$(n-1)\times(n-1)$的复矩阵都存在Schur分解，以下证明$n\times n$情形。
%	
%	首先，由于复系数多项式有根定理，$A$必存在一个特征值$\lambda_1\in \mathbb{C}$，取相应的单位特征向量为$u_1\in \mathbb{C}^n$（$\|u_1\|=1$）。将$u_1$扩充成$\mathbb{C}^n$的一组正交基$\{u_1,u_2,\dots,u_n\}$（可用Gram-Schmidt法对任意基规范化得到）。构造酉矩阵$Q_1 = [u_1,\dots,u_n]\in M_n(\mathbb{C})$（第一列取$u_1$）。则
%	\[ Q_1^* A Q_1 = \begin{pmatrix}
%		\lambda_1 & w^* \\
%		\mathbf{0} & A_1
%	\end{pmatrix}, \] 
%	其中$\mathbf{0}$表示$(n-1)\times 1$零向量，$w^*\in \mathbb{C}^{1\times (n-1)}$，而$A_1$为$A$在$u_1$所在一维子空间的正交补上的表示矩阵，$A_1\in M_{(n-1)}(\mathbb{C})$。由于$Q_1$的选取，$A_1$等于$A$在该子空间的限制，$A_1$即为一个$(n-1)\times(n-1)$矩阵。由归纳假设，$A_1$存在一个酉矩阵$Q_2\in M_{n-1}(\mathbb{C})$，使得 
%	\[ Q_2^* A_1 Q_2 = T_1 \] 
%	为上三角矩阵。将$Q_2$扩充成$n\times n$块酉矩阵$\hat{Q}_2=\begin{pmatrix}1 & \mathbf{0}^* \\ \mathbf{0} & Q_2\end{pmatrix}$，则定义$Q = Q_1 \hat{Q}_2$是一个$n\times n$酉矩阵，并且：
%	\[ Q^* A Q = \hat{Q}_2^* Q_1^* A Q_1 \hat{Q}_2 = \hat{Q}_2^* \begin{pmatrix} \lambda_1 & w^* \\ \mathbf{0} & A_1 \end{pmatrix}\hat{Q}_2 = \begin{pmatrix}\lambda_1 & w'^* \\ \mathbf{0} & T_1 \end{pmatrix}. \] 
%	由于$\hat{Q}_2$对$\begin{pmatrix}\lambda_1 & w^*\\ \mathbf{0} & A_1\end{pmatrix}$的第一行除了对角元$\lambda_1$以外的元素起了酉变换作用，上式所得矩阵仍是上三角形矩阵：
%	\[ Q^* A Q = \begin{pmatrix}
%		\lambda_1 & * & \cdots & * \\
%		0 & * & \cdots & * \\
%		\vdots & \vdots & \ddots & \vdots \\
%		0 & 0 & \cdots & *
%	\end{pmatrix}, \] 
%	其中对角线依次由$\lambda_1$及$T_1$的对角线元素组成。这就得到了$A$的Schur上三角形式。
%\end{proof}
%
%由Schur分解可立即推出矩阵的一些重要性质。例如，上三角矩阵$T$的对角线恰为矩阵的特征值，因此有：
%
%\begin{corollary}\label{cor:trace-det-eig}
%	任意$A\in M_n(\mathbb{C})$的特征值（代数重数计）之和等于$\tr(A)$，特征值之积等于$\det(A)$。
%\end{corollary}
%\begin{proof}
%	取$A$的Schur分解$A=Q T Q^*$，则$\tr(A) = \tr(T) = \sum_{i=1}^n T_{ii} = \sum_{i=1}^n \lambda_i$，其中$\lambda_i$为$A$的$n$个特征值。而$\det(A) = \det(T)$（因为$Q$酉矩阵$\det(Q)\neq 0$且$|\det(Q)|=1$），而$\det(T) = \prod_{i=1}^n T_{ii} = \prod_{i=1}^n \lambda_i$。因此命题成立。
%\end{proof}
%
%\begin{corollary}[谱定理]\label{cor:Spectral}
%	设$A\in M_n(\mathbb{R})$是对称矩阵，则存在正交矩阵$Q$使得 
%	\[ Q^T A\,Q = D, \] 
%	其中$D$是对角矩阵，其对角线元素为$A$的$n$个实特征值。这意味着$A$是正交对角可相似对角化的。对于Hermitian矩阵（自伴矩阵）也有类似结论：存在酉矩阵将其相似对角化。
%\end{corollary}
%\begin{proof}
%	由Schur分解，对称实矩阵$A$可写为$A=Q T Q^T$，其中$Q$正交，$T$上三角。因为$A$对称，有$A= A^T$，所以
%	\[ T = Q^T A Q = (Q^T A Q)^T = Q^T A^T Q = Q^T A Q = T^T. \] 
%	这说明$T$同时是上三角和对称矩阵，因此$T$必须是对角矩阵。于是$A = Q T Q^T$成为$A$的正交相似对角化形式。由于$A$实对称的特征值都为实数，$T$对角线上元素就是$A$的$n$个实特征值。
%\end{proof}
%
%\begin{note}
%	Schur分解的一个重要理论应用是证明任意两个可交换矩阵可以被同一个酉（或正交）矩阵同时（三角）相似化。具体而言，如果$AB=BA$且$A,B\in M_n(\mathbb{C})$，那么存在一个酉矩阵$U$使得
%	\[ U^* A U = T_A,\qquad U^* B U = T_B, \] 
%	其中$T_A,T_B$都是上三角矩阵。并且$T_A$和$T_B$可以被选择为“同时上三角”，也就是说它们在同一酉基下均为上三角形。这个命题可以通过对$A$作Schur分解并利用$B$与$A$的可交换性来递归构造实现。当$A,B$进一步是对角izable而且互相可交换时，它们甚至可以在同一正交基下同时对角化——例如当$A,B$都是对称矩阵且$AB=BA$时，它们共享一组正交特征向量，可被同一正交矩阵同时对角化。
%\end{note}
%
%\begin{note}
%	Schur分解在数值计算中特别重要。实际求解特征值问题时，通常先通过相似变换将矩阵化为Hessenberg矩阵或对称情形下的三对角矩阵（这可以看作是Schur分解的前半步骤），再使用QR迭代算法逐步逼近Schur形式。QR算法在大多数情况下后向稳定，能够较准确地计算出矩阵的全部特征值。当矩阵的特征值彼此距离很近时，结果可能不太稳定，但这反映的是问题本身的敏感性而非算法缺陷。通过Schur分解得到上三角$T$后，可以直接读取特征值并进一步计算特征向量。需要注意的是，对于非正交相似对角化的矩阵（即不正常矩阵），其特征值可能对小扰动非常敏感，其特征向量的条件数也可能很高。这时计算得到的Schur分解虽然可靠地给出了特征值，但是特征向量的数值稳定性要差一些。
%\end{note}
%
%\subsection{秩揭示QR分解（RRQR）}
%对于一些矩阵而言，标准的QR分解并不足以直接看出矩阵的数值秩或独立列的情况。秩揭示QR分解（Rank-Revealing QR, 简称RRQR）通过在QR分解过程中交换列的策略，使得$R$的对角线元素按大小递减排列，从而“揭示”矩阵的秩及接近奇异的程度。
%
%\begin{theorem}\label{theo:RRQR}
%	设$A\in M_{m\times n}(\mathbb{R})$，通过列主元（选主列）QR分解可以得到置换矩阵$P$、正交矩阵$Q$和上三角矩阵$R$，使得 
%	\[ A P = Q \begin{pmatrix} R_{11} & R_{12} \\ \mathbf{0} & R_{22} \end{pmatrix}, \] 
%	其中$R_{11}\in M_{r}(\mathbb{R})$是$r=\rank(A)$阶的上三角块，非奇异；$R_{22}\in M_{m-r \times n-r}(\mathbb{R})$为一个（近似）零矩阵；而$R_{12}\in M_{r\times (n-r)}$。特别地，当$A$恰好秩为$r$时，$R_{22}$块严格为零矩阵。
%\end{theorem}
%\begin{proof}
%	我们使用带列选主元的Householder QR算法对$A$进行分解。在每一步分解$A$的过程中，先在尚未处理的列中选取2-范数最大的列作为主列，通过交换列操作（等价于右乘适当的置换矩阵）将其移至当前处理位置。然后应用Householder反射将该列的当前主元下面的元素全部消去为零，并对剩余列进行相应的正交变换。如此迭代进行。当处理完$r$个非零主元列后，若$\rank(A)=r$，则剩余的列全部为零列；若$A$近似奇异而$\rank(A)$数值上为$r$，则剩余列的范数将非常小。将所有Householder变换累积为正交矩阵$Q$，所有列交换操作累积为置换矩阵$P$，我们就得到
%	\[ A P = Q \begin{pmatrix} R_{11} & R_{12} \\ \mathbf{0} & R_{22} \end{pmatrix}, \] 
%	其中$R_{11}$对应选取的主列之间的变换关系，因为每一步都选取了最大列，大致有$\|R_{11}(i,i)\| \ge \|R_{11}(j,j)\|$对于$i<j$，也即$R$的对角元按绝对值递减排列。当$A$秩为$r$时，在理想精确算术下，$R_{22}$严格为零；在数值处理中，$R_{22}$将包含非常小的元素，从而指示了“数值秩”的大小。
%\end{proof}
%
%利用上述定理，可以有效分析矩阵的秩和奇异值大小关系。特别地，$R_{11}$的对角线提供了$A$的主要奇异值量级的估计，而$R_{22}$的小元素则表示对应列向量几乎可以由前$r$列线性表示。
%
%\begin{algorithm}[!ht]
%	\caption{带列主元的QR分解（RRQR）}\label{alg:RRQR}
%	\begin{algorithmic}[1]
%		\REQUIRE $A\in \mathbb{R}^{m\times n}$
%		\ENSURE $P, Q, R$使$AP = QR$，其中$Q$为$m\times m$正交矩阵，$R$为$m\times n$的上三角分块矩阵。
%		\STATE 初始化$P = I_n,\;Q = I_m,\;R = A$。
%		\FOR{$k = 1$ \TO $\min(m,n)$}
%		\STATE 在列索引$k$到$n$中选取$\ell$使$\|R[\,k:m,\; \ell]\,\|_2 = \max_{j\ge k} \|R[\,k:m,\; j]\,\|_2$。\quad // 寻找剩余列中范数最大的列
%		\STATE 交换$R$的第$k$列和第$\ell$列（同时交换$P$的第$k$列和第$\ell$列）。
%		\STATE 提取当前列$R[k:m,\;k]$作为向量$x$。
%		\IF{$\|x\|_2 = 0$} 
%		\STATE \textbf{break}。\quad // 若当前列范数为0，说明剩余列均为0
%		\ENDIF
%		\STATE 构造Householder变换矩阵$H_k$，使其作用下$H_k x = (\alpha,0,\dots,0)^T$（$\alpha = -\sign(x_1)\|x\|_2$）。
%		\STATE 将$H_k$嵌入为$\hat{H}_k = \begin{pmatrix} I_{k-1} & \mathbf{0}\\ \mathbf{0} & H_k \end{pmatrix}$作用于$R$：$R \leftarrow \hat{H}_k\,R$。
%		\STATE $Q \leftarrow Q\,\hat{H}_k^T$。\quad // 累乘正交变换
%		\ENDFOR
%		\RETURN $P,Q,R$。
%	\end{algorithmic}
%\end{algorithm}
%
%\begin{note}
%	在以上RRQR算法中，每一步都选取剩余列中范数最大的列来做主元，因此可以保证$R$的对角线元素按非增顺序排列。这种策略使$R$的对角线与$A$的奇异值大小具有相同的排序趋势，从而直观上“揭示”了矩阵的秩。当$A$的数值秩为$r$时，我们将在$R$的对角线上观察到从$r$到$r+1$位置处出现陡峭下降（或者后面的对角元非常接近0）。实践证明，带列主元的QR分解在判断矩阵秩方面相当可靠。然而，在理论上，RRQR并不能保证得到与最优截断奇异值近似相同的误差界——某些极端矩阵会使简单的贪心策略失效。为此，研究者提出了“强秩揭示QR分解”等改进算法，通过调整列选取策略以获得更严格的误差界。但在大多数应用场景下，上述基本RRQR已足以提供有价值的秩估计信息。
%\end{note}
%
%\begin{note}
%	RRQR分解的重要应用之一是在求解秩亏损的最小二乘问题中确定一个良好的列子集。从$AP=QR$结果可以看出，前$r$列经过交换后构成的$A[:,1:r]$是$A$列空间的一组基，后面的列几乎都可以由前$r$列线性表示。因此，我们可以通过舍弃$R_{22}$部分，将$A$近似表示为$A \approx Q \begin{pmatrix} R_{11} & R_{12} \\ \mathbf{0} & \mathbf{0} \end{pmatrix} P^T = (Q[:,1:r] R_{11}) (P^T)_{{1:r},:}$。这里$C = Q[:,1:r]R_{11}$是$A$的一组近似列基，$P^T_{1:r,:}$对应选择的$r$列，$A\approx C (P^T_{1:r,:})$提供了一个秩$r$的近似。简言之，RRQR可以用于列子集选取（Column Subset Selection），通过选择$A$的若干列来近似表征$A$的全部列。与SVD相比，这种方法得到的近似虽然在误差上通常稍逊，但具有结果可解释、列实际存在于原矩阵中等优点，在信号处理和数据分析中有广泛应用。
%\end{note}
%
%\subsection{消去矩阵与相似变换}
%\paragraph{消去矩阵：} 消去矩阵是表示基本行操作的矩阵。对于矩阵$A$，如果希望用第$j$行的某个倍数去消去第$i$行的某个元素（典型情况是用第$j$行消去第$i$行的第$j$列元素），定义
%\[ E_{ij}(\lambda) = I_n - \lambda\, e_i e_j^T, \] 
%其中$e_k$为第$k$个标准基向量。当$E_{ij}(\lambda)$左乘$A$时，相当于执行了$R_i \leftarrow R_i - \lambda R_j$的行变换（这里$R_i$表示$A$的第$i$行）。这种$E_{ij}(\lambda)$矩阵是单位下三角矩阵，其对角线元素为1，在$(i,j)$位置为$-\lambda$，其余非对角元与单位矩阵相同。显然$E_{ij}(\lambda)$是可逆的，其逆矩阵$E_{ij}(\lambda)^{-1} = E_{ij}(-\lambda)$仍是同类型矩阵。
%
%利用消去矩阵，可以形式化地表示高斯消去过程。例如，通过一系列消去矩阵左乘，我们可以将$A$化为上三角矩阵$U$：
%\[ E_{p}\cdots E_2 E_1\,A = U, \] 
%其中$E_k$表示第$k$步选定主元后的所有消去操作对应的矩阵。于是，
%\[ A = (E_{p}\cdots E_2 E_1)^{-1} U. \] 
%注意到$E_{p}\cdots E_2 E_1$是一个下三角可逆矩阵（其对角线也全为1），因此可记$L^{-1} = E_{p}\cdots E_2 E_1$，从而$A = L U$。这就是LU分解，其中$L$恰由各步消去矩阵的逆乘积给出。可见消去矩阵提供了一种理解$LU$分解的视角：$L$囊括了将$A$化为$U$的所有初等行操作。
%
%\paragraph{相似变换：} 在矩阵理论中，如果存在可逆矩阵$S$使得 
%\[ B = S^{-1} A S, \] 
%则称矩阵$A$与$B$相似（similar）。相似关系是矩阵在抽象线性变换意义下的一种等价关系：$A$与$B$相似表示它们表示的是同一个线性算子在不同基下的坐标表示。相似矩阵共享许多代数性质：
%
%\begin{proposition}
%	若$B = S^{-1} A S$，则$A$与$B$具有相同的特征多项式和特征值，并且$\tr(A)=\tr(B)$，$\det(A)=\det(B)$。
%\end{proposition}
%\begin{proof}
%	由$B=S^{-1}AS$可得
%	\[ \det(\lambda I - B) = \det(\lambda I - S^{-1}AS) = \det(S^{-1}(\lambda I - A)S) = \det(S^{-1}) \det(\lambda I - A) \det(S) = \det(\lambda I - A). \] 
%	因此$A$与$B$特征多项式相同，因而全部特征值相同。又因为$\tr(X)$等于特征值之和，$\det(X)$等于特征值之积，上式也直接推出$\tr(A) = \tr(B)$和$\det(A) = \det(B)$。
%\end{proof}
%
%根据以上性质，如果$A$与$B$相似，那么它们在线性代数意义下并无本质区别：它们的秩、特征值、特征向量结构等都紧密相关（严格地说，特征向量本身不会一一对应，但特征子空间维数对应，且$S$提供了各自特征子空间之间的对应关系）。实际中，一个矩阵往往通过与其相似的更简单形态来分析，例如对角化或Jordan标准形。这也是Schur分解、谱分解以及Jordan分解等的理论基础。
%
%\begin{note}
%	相似变换与消去的过程有所不同：消去操作是左乘消去矩阵，相当于对矩阵执行特定的行初等变化。而相似变换$B=S^{-1}AS$则等价于同时对$A$进行一系列行变换和列变换（对应$S^{-1}$和$S$）。这保证了相似变换不会改变$A$的特征值。在数值计算时，如果$S$的条件数很大（即$S$接近奇异），相似变换将扩大舍入误差，使结果难以精确解释。因此在实际算法中，通常希望使用正交（或酉）相似变换，因为此时$S$正交，条件数为1，不扩大误差。例如，在Schur分解和QR算法中，我们坚持使用酉（正交）相似变换来逐步化简矩阵，从而保证数值稳定性。
%\end{note}
