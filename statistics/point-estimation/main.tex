\chapter{点估计理论}

\begin{definition}
	设$(X,\mathscr{A},\mathscr{P})$是参数结构，$\Theta$是参数空间，$\mathbf{X}=(\seq{X}{n})$为从总体$F$中抽取的简单样本，$g$是定义在$\Theta$上的函数，它是一个\gls{Estimand}，一般默认它为实数。若将样本的可测函数$\delta(\mathbf{X})$作为$g(\theta)$的估计，称这种估计方式为\gls{PointEstimation}，$\delta(\mathbf{X})$被称为$g(\theta)$的\gls{Estimator}。
\end{definition}
\begin{definition}
	设$(X,\mathscr{A},\mathscr{P})$是参数统计结构，$\Theta$是参数空间，$\mathbf{X}=(\seq{X}{n})$为从总体$F$中抽取的简单样本，$g(\theta)$是定义在$\Theta$上的函数，$\delta(\mathbf{X})$是$g(\theta)$的一个估计量。如果：
	\begin{equation*}
		\forall\;\theta\in\Theta,\;\operatorname{E}_{\theta}[\delta(\mathbf{X})]=g(\theta)
	\end{equation*}
	则称$\delta(\mathbf{X})$为$g(\theta)$的一个\gls{UnbiasedEstimation}。若$g(\theta)$存在无偏估计量，则称$g(\theta)$\gls{UEstimable}。
\end{definition}
\begin{property}\label{prop:0UnbiasedEstimator}
	称满足$\operatorname{E}_{\theta}[\delta(\mathbf{X})]=0$的估计量$\delta(\mathbf{X})$为\textbf{零无偏估计量}，它具有如下性质：
	\begin{enumerate}
		\item 设$\delta$是待估量$g(\theta)\in\mathbb{R}^{}$的无偏估计量，所有$g(\theta)$的无偏估计量为$\{\delta-f:\operatorname{E}_{\theta}[f(\mathbf{X})]=0\}$；
		\item 
	\end{enumerate}
\end{property}
\begin{proof}
	(1)估计量$\delta_1$为$g(\theta)$的无偏估计量当且仅当$\operatorname{E}_{\theta}(\delta)=\operatorname{E}_{\theta}(\delta_1)-0$，由\cref{prop:MeasurableIntegral}(5)可得充分性。假设$\delta_2$不可以表示为$\delta$与一个零无偏估计$f$的和，由\cref{prop:MeasurableIntegral}(5)可知$\operatorname{E}_{\theta}(\delta_2-\delta)=\operatorname{E}(\delta_2)-\operatorname{E}(\delta)\ne0$，$\delta_2$不是$g(\theta)$的无偏估计量，必要性得证。
\end{proof}
\begin{definition}
	设$(X,\mathscr{A},\mathscr{P})$是参数结构，$\Theta$是参数空间，$\mathbf{X}=(\seq{X}{n})$为从总体$F$中抽取的简单样本，$g(\theta)$是定义在$\Theta$上的函数，$\delta(\mathbf{X})$是$g(\theta)$的一个估计量。如果：
	\begin{equation*}
		\forall\;\theta\in\Theta,\;\lim_{n\to+\infty}\operatorname{E}_{\theta}[\delta_n(\mathbf{X})]=g(\theta)
	\end{equation*}
	则称$\delta_n(\mathbf{X})$为$g(\theta)$的一个\gls{AsymptoticallyUnbiasedEstimation}。
\end{definition}
\begin{definition}
	设$(X,\mathscr{A},\mathscr{P})$是参数结构，$\Theta$是参数空间，$\mathbf{X}=(\seq{X}{n})$为从总体$F$中抽取的简单样本，$g(\theta)$是定义在$\Theta$上的函数，$\delta(\mathbf{X})$是$g(\theta)$的一个估计量，$\delta_1(\mathbf{X}),\delta_2(\mathbf{X})$是$g(\theta)$的两个不同的无偏估计量。若：
	\begin{equation*}
		\forall\;\theta\in\Theta,\;\operatorname{Var}_{\theta}[\delta_1(\mathbf{X})]\leqslant\operatorname{Var}_{\theta}[\delta_2(\mathbf{X})]
	\end{equation*}
	且至少存在一个$\theta\in\Theta$使得小于号成立，则称估计量$\delta_1(\mathbf{X})$比$\delta_2(\mathbf{X})$\textbf{有效}。
\end{definition}
\begin{definition}
	设$(X,\mathscr{A},\mathscr{P})$是参数结构，$\Theta$是参数空间，$\mathbf{X_n}=(\seq{X}{n})$为从总体$F$中抽取的简单样本，$g(\theta)$是定义在$\Theta$上的函数，$\delta(\mathbf{X})$是$g(\theta)$的一个估计量。若$\delta(\mathbf{X_n})\overset{P}{\longrightarrow}g(\theta)$，则称$\delta(\mathbf{X})$是$g(\theta)$的\gls{WeaklyConsistentEstimation}。若$\delta(\mathbf{X_n})\overset{\text{a.s.}}{\longrightarrow}g(\theta)$，则称$\delta(\mathbf{X})$是$g(\theta)$的\gls{StronglyConsistentEstimation}。若：
	\begin{equation*}
		\lim_{n\to+\infty}\operatorname{E}_{\theta}[|\delta(\mathbf{X_n})-g(\theta)|^r]=0
	\end{equation*}
	则称$\delta(\mathbf{X})$是$g(\theta)$的\textbf{r阶矩相合估计}，当$r=2$时称$\delta(\mathbf{X})$是$g(\theta)$的\textbf{均方相合估计}。
\end{definition}

\input{statistics/point-estimation/UMVUE.tex}
\input{statistics/point-estimation/Moment-Estimator.tex}
\input{statistics/point-estimation/MLE.tex}

\begin{theorem}
	对于样本方差和样本均值：
	\begin{enumerate}
		\item 记：
		\begin{equation*}
			\bar{x}_n=\frac{1}{n}\sum_{i=1}^{n}x_i,\quad s_n^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x}_n)^2
		\end{equation*}
		则有：
		\begin{equation*}
			\bar{x}_{n+1}=\bar{x}_n+\frac{1}{n+1}(x_{n+1}-\bar{x}_n),\quad s_{n+1}^2=\frac{n-1}{n}s_n^2+\frac{1}{n}(x_{n+1}-\bar{x}_n)^2
		\end{equation*}
		\item 从同一总体中抽取两个大小分别为$m$和$n$的样本，样本均值分别记为$\bar{x}_1,\bar{x}_2$，样本方差分别为$s_1^2,s_2^2$，将两组样本合并，其均值和样本方差分别为$\bar{x},s^2$，则有：
		\begin{equation*}
			\bar{x}=\frac{m\bar{x}_1+n\bar{x}_2}{m+n},\quad s^2=\frac{(m-1)s_1^2+(n-1)s_2^2}{m+n-1}+\frac{mn(\bar{x}_1-\bar{x}_2)^2}{(m+n)(m+n+1)}
		\end{equation*}
	\end{enumerate}
\end{theorem}
\begin{proof}
	(1)对于均值有：
	\begin{align*}
		\bar{x}_{n+1}&=\frac{1}{n+1}\sum_{i=1}^{n+1}x_i=\frac{n}{n+1}\frac{1}{n}\left(\sum_{i=1}^{n}x_i+x_{n+1}\right) \\
		&=\frac{n}{n+1}\bar{x}_n+\frac{1}{n+1}x_{n+1}=\bar{x}_n+\frac{1}{n+1}(x_{n+1}-\bar{x}_n)
	\end{align*}
	对于方差有：
	\begin{align*}
		s_{n+1}^2&=\frac{1}{n}\sum_{i=1}^{n+1}(x_i-\bar{x}_{n+1})^2=\frac{1}{n}\sum_{i=1}^{n+1}\left[x_i-\bar{x}_n-\frac{1}{n+1}(x_{n+1}-\bar{x}_n)\right]^2 \\
		&=\frac{1}{n}\sum_{i=1}^{n+1}\left[(x_i-\bar{x}_n)^2+\frac{1}{(n+1)^2}(x_{n+1}-\bar{x}_n)^2-\frac{2}{n+1}(x_i-\bar{x}_n)(x_{n+1}-\bar{x}_n)\right] \\
		&=\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x}_n)^2+\frac{1}{n}(x_{n+1}-\bar{x}_n)^2+\frac{1}{n(n+1)}(x_{n+1}-\bar{x}_n)^2-\frac{2}{n(n+1)}(x_{n+1}-\bar{x}_n)^2 \\
		&=\frac{n-1}{n}s_n^2+\frac{1}{n}(x_{n+1}-\bar{x}_n)^2-\frac{1}{n(n+1)}(x_{n+1}-\bar{x}_n)^2 \\
		&=\frac{n-1}{n}s_n^2+\frac{1}{n}(x_{n+1}-\bar{x}_n)^2
	\end{align*}\par
	(2)均值的结论是显然的，对于方差有：
	\begin{align*}
		s^2&=\frac{1}{m+n-1}\sum_{i=1}^{m+n}(x_i-\bar{x})^2=\frac{1}{m+n-1}\left[\sum_{i=1}^{m}(x_i-\bar{x})^2+\sum_{i=m+1}^{m+n}(x_i-\bar{x})^2\right] \\
		&=\frac{1}{m+n-1}\left[\sum_{i=1}^{m}(x_i-\bar{x}_1+\bar{x}_1-\bar{x})^2+\sum_{i=m+1}^{m+n}(x_i-\bar{x}_2+\bar{x}_2-\bar{x})^2\right] \\
		&=\frac{1}{m+n-1}\left[(m-1)s_1^2+m(\bar{x}_1-\bar{x})^2+2\sum_{i=1}^{m}(x_i-\bar{x}_1)(\bar{x_1}-\bar{x})\right. \\
		&\quad\left.+(n-1)s_2^2+n(\bar{x}_2-\bar{x})^2+2\sum_{i=m+1}^{m+n}(x_i-\bar{x}_2)(\bar{x_2}-\bar{x})\right] \\
		&=\frac{1}{m+n-1}\left[(m-1)s_1^2+m(\bar{x}_1-\bar{x})^2+(n-1)s_2^2+n(\bar{x}_2-\bar{x})^2\right] \\
		&=\frac{(m-1)s_1^2+(n-1)s_2^2}{m+n-1}+\frac{m(\bar{x}_1-\bar{x})^2+n(\bar{x}_2-\bar{x})^2}{m+n-1}
	\end{align*}
	由于：
	\begin{gather*}
		m(\bar{x}_1-\bar{x})^2=m\left(\bar{x}_1-\frac{m\bar{x}_1+n\bar{x}_2}{m+n}\right)^2=m\frac{n^2(\bar{x}_1-\bar{x}_2)^2}{(m+n)^2} \\
		n(\bar{x}_2-\bar{x})^2=n\left(\bar{x}_2-\frac{m\bar{x}_1+n\bar{x}_2}{m+n}\right)^2=n\frac{m^2(\bar{x}_1-\bar{x}_2)^2}{(m+n)^2}
	\end{gather*}
	所以：
	\begin{align*}
		s^2&=\frac{(m-1)s_1^2+(n-1)s_2^2}{m+n-1}+\frac{m(\bar{x}_1-\bar{x})^2+n(\bar{x}_2-\bar{x})^2}{m+n-1} \\
		&=\frac{(m-1)s_1^2+(n-1)s_2^2}{m+n-1}+\frac{(m+n)mn(\bar{x}_1-\bar{x}_2)^2}{(m+n-1)(m+n)^2} \\
		&=\frac{(m-1)s_1^2+(n-1)s_2^2}{m+n-1}+\frac{mn(\bar{x}_1-\bar{x}_2)^2}{(m+n-1)(m+n)}\qedhere
	\end{align*}
\end{proof}

