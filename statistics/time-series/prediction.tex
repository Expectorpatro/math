\section{预测}

\subsection{最佳线性预测}
\begin{definition}
	设$Y$是方差有限的随机变量，$\mathbf{X}=(\seq{\mathbf{X}}{n})^{\top}$是各分量方差有限的随机向量，$\operatorname{E}(Y)=b,\;\operatorname{E}(\mathbf{X})=\boldsymbol{\mu}$。若$\alpha\in\mathbb{R}^{n}$使得对任意的$\beta\in\mathbb{R}^{n}$都有：
	\begin{equation*}
		\operatorname{E}\{[Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]^2\}\leqslant\operatorname{E}\{[Y-\beta^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]^2\}
	\end{equation*}
	则称$a^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$是用$\mathbf{X}$对$Y$进行预测时的\textbf{最佳线性预测}，记为$L(Y|\mathbf{X})$。
\end{definition}
\begin{definition}
	若$\operatorname{Cov}(\mathbf{X})$与$\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$已知，称$\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$为\textbf{预测方程}。
\end{definition}
\begin{property}\label{prop:BestLinearForcast}
	设$Y$是方差有限的随机变量，$\mathbf{X}=(\seq{\mathbf{X}}{n})^{\top}$是各分量方差有限的随机向量，$\operatorname{E}(Y)=b,\;\operatorname{E}(\mathbf{X})=\boldsymbol{\mu}$。用$\mathbf{X}$对$Y$进行预测时的最佳线性预测具有如下性质：
	\begin{enumerate}
		\item 最佳线性预测是无偏预测，它的含义是$\operatorname{E}[L(Y|\mathbf{X})]=\operatorname{E}(Y)$；
		\item 若$\alpha\in\mathbb{R}^{n}$使得$\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$，则$L(Y|\mathbf{X})=\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$，且有：
		\begin{equation*}
			\operatorname{E}\{[Y-L(Y|\mathbf{X})]^2\}=\operatorname{E}[(Y-b)^2]-\alpha^{\top}\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{Var}(Y)-\alpha^{\top}\operatorname{Cov}(\mathbf{X})\alpha
		\end{equation*}
		\item 若$\operatorname{Cov}(\mathbf{X})$可逆，则$\alpha^{-1}=\operatorname{Cov}(\mathbf{X})^{-1}\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$；
		\item 若$\det[\operatorname{Cov}(\mathbf{X})]=0$，取正交矩阵$Q$使得：
		\begin{equation*}
			Q\operatorname{Cov}(\mathbf{X})Q^{\top}=\operatorname{diag}\{\seq{\lambda}{r},0,0,\dots,0\},\quad\lambda_i>0,\;i=1,2,\dots,r
		\end{equation*}
		定义$\mathbf{Z}=Q(\mathbf{X}-\boldsymbol{\mu})=(\seq{\mathbf{Z}}{r},0,0,\dots,0)^{\top},\;\varepsilon=(\seq{\mathbf{Z}}{r})^{\top}$，则$\operatorname{E}(\varepsilon\varepsilon^{\top})$正定，并且对$\alpha=[\operatorname{E}(\varepsilon\varepsilon^{\top})]^{-1}\operatorname{E}[\varepsilon(Y-b)]$，有$L(Y|\mathbf{X})=\alpha^{\top}\varepsilon+b$；
		\item 预测方程$\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$一定有解；
		\item 预测方程$\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$的解可能不唯一，但$L(Y|\mathbf{X})$是在几乎处处的意义上唯一的，并且若一个随机变量几乎处处等于$L(Y|\mathbf{X})$，它也是一个最佳线性预测；
		\item 若$\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]=\mathbf{0}$，则$L(Y|\mathbf{X})=b\;$a.e.；
		\item 若$Y=a^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$，则$L(Y|\mathbf{X})=Y\;$a.e.；
		\item
		$a^{\top}(\mathbf{X}-\boldsymbol{\mu})+b=L(Y|\mathbf{X})$的充分必要条件为：
		\begin{equation*}
			\operatorname{E}\{(\mathbf{X}-\boldsymbol{\mu})[Y-a^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]\}=\mathbf{0}
		\end{equation*}
		\item $L(\cdot|\mathbf{X})$是一个线性运算：
		\begin{equation*}
			L\left(\sum_{i=1}^{n}k_iY_i|\mathbf{X}\right)=\sum_{i=1}^{n}k_iL(Y_i|\mathbf{X})
		\end{equation*}
		\item 设$\mathbf{Z}=(\seq{\mathbf{Z}}{m})^{\top}$，若$\operatorname{Cov}(\mathbf{X},\mathbf{Z})=\mathbf{0}$，则有$L(Y|\mathbf{X},\mathbf{Z})=L(Y|\mathbf{X})+L(Y|\mathbf{Z})$；
		\item 设$\hat{Y}=L(Y|\mathbf{X}),\;\tilde{Y}=L(Y|\seq{\mathbf{X}}{n-1})$，则：
		\begin{equation*}
			L(\hat{Y}|\seq{\mathbf{X}}{n-1})=\tilde{Y},\quad\operatorname{E}[(Y-\hat{Y})^2]\leqslant\operatorname{E}[(Y-\tilde{Y})^2]
		\end{equation*}
		\item 设$\mathbf{X}=\seq{\mathbf{Z}}{m}$，若存在矩阵$A,B$使得$\mathbf{X}=A\mathbf{Z},\;\mathbf{Z}=B\mathbf{X}$，则$L(Y|\mathbf{X})=L(Y|\mathbf{Z})$。
	\end{enumerate}
\end{property}
\begin{proof}
	(1)设$L(Y|\mathbf{X})=\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$，则：
	\begin{equation*}
		\operatorname{E}[L(Y|\mathbf{X})]=\operatorname{E}[\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b]=\alpha^{\top}\operatorname{E}(\mathbf{X}-\boldsymbol{\mu})+b=b=\operatorname{E}(Y)
	\end{equation*}\par
	(2)对任意的$\beta\in\mathbb{R}^{n}$，由\cref{prop:MeasurableIntegral}(5)可得：
	\begin{align*}
		&\operatorname{E}\{[Y-b-\beta^{\top}(\mathbf{X}-\boldsymbol{\mu})]^2\} \\
		=&\operatorname{E}\{[Y-b-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})][Y-b-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]\} \\
		=&\operatorname{E}\{(Y-b)^2-2[Y-b-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})](\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})+[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\} \\
		=&\operatorname{E}[(Y-b)^2]+\operatorname{E}\{[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\}-2\operatorname{E}\{[Y-b-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})](\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})\} \\
		=&\operatorname{E}[(Y-b)^2]+\operatorname{E}\{[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\}-2(\alpha^{\top}-\beta^{\top})\operatorname{E}[(Y-b)(\mathbf{X}-\boldsymbol{\mu})-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})] \\
		=&\operatorname{E}[(Y-b)^2]+\operatorname{E}\{[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\}-2(\alpha^{\top}-\beta^{\top})\{\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]-\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^{\top}\alpha]\} \\
		=&\operatorname{E}[(Y-b)^2]+\operatorname{E}\{[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\}-2(\alpha^{\top}-\beta^{\top})\{\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]-\operatorname{Cov}(\mathbf{X})\alpha\}
	\end{align*}
	因为$\operatorname{Cov}(\mathbf{X})=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$，所以上式第三项为$0$，而前两项都是非负的，其中第二项为$0$当且仅当$\alpha=\beta$，由最佳线性预测的定义，$L(Y|\mathbf{X})=\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$。由\cref{prop:MeasurableIntegral}(5)和\cref{prop:CovMat}(3)可得：
	\begin{align*}
		&\operatorname{E}\{[Y-L(Y|\mathbf{X})]^2\}=\operatorname{E}\{[Y-b-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})]^2\} \\
		=&\operatorname{E}\{(Y-b)^2-2\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})(Y-b)+\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})\} \\
		=&\operatorname{E}[(Y-b)^2]-2\alpha^{\top}\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]+\operatorname{E}[\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})\alpha] \\
		=&\operatorname{E}[(Y-b)^2]-2\alpha^{\top}\operatorname{Cov}(\mathbf{X})\alpha+\alpha^{\top}\operatorname{Cov}(\mathbf{X})\alpha \\
		=&\operatorname{E}[(Y-b)^2]-\alpha^{\top}\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{Var}(Y)-\alpha^{\top}\operatorname{Cov}(\mathbf{X})\alpha
	\end{align*}\par
	(3)显然。\par
	(4)由\cref{prop:CovMat}(2)可得$\operatorname{Cov}(\mathbf{X})$是一个半正定矩阵，根据\cref{prop:HermitianMatEigen}(3)和\cref{theo:PositiveSemidefinite}(3.5)可知存在正交矩阵$Q$使得：
	\begin{equation*}
		Q\operatorname{Cov}(\mathbf{X})Q^{\top}=\operatorname{diag}\{\seq{\lambda}{r},0,0,\dots,0\},\quad\lambda_i>0,\;i=1,2,\dots,r
	\end{equation*}
	注意到：
	\begin{equation*}
		\operatorname{E}(\mathbf{Z})=\mathbf{0},\quad\operatorname{Cov}(\mathbf{Z})=\operatorname{E}(\mathbf{Z}\mathbf{Z}^{\top})=Q\operatorname{Cov}(\mathbf{X})Q^{\top}=\operatorname{diag}\{\seq{\lambda}{r},0,0,\dots,0\}
	\end{equation*}
	所以：
	\begin{equation*}
		\operatorname{E}(\varepsilon\varepsilon^{\top})=\operatorname{Cov}(\varepsilon)=\operatorname{diag}\{\seq{\lambda}{r}\}
	\end{equation*}
	于是$\operatorname{E}(\varepsilon\varepsilon^{\top})$的特征值都大于$0$，由\cref{theo:PositiveDefinite}(3.5)可知$\operatorname{E}(\varepsilon\varepsilon^{\top})$正定。取$\alpha=[\operatorname{E}(\varepsilon\varepsilon^{\top})]^{-1}\operatorname{E}[\varepsilon(Y-b)]$，则：
	\begin{gather*}
		\operatorname{E}(\varepsilon\varepsilon^{\top})\alpha=\operatorname{E}[\varepsilon(Y-b)] \\
		\operatorname{diag}\{\seq{\lambda}{r}\}\alpha=\operatorname{E}[\varepsilon(Y-b)] \\
		\operatorname{diag}\{\seq{\lambda}{r},0,0,\dots,0\}
		\begin{pmatrix}
			\alpha \\
			\mathbf{0}	
		\end{pmatrix}=\operatorname{E}[Z(Y-b)] \\
		Q\operatorname{Cov}(\mathbf{X})Q^{\top}
		\begin{pmatrix}
			\alpha \\
			\mathbf{0}	
		\end{pmatrix}=\operatorname{E}[Q(\mathbf{X}-\boldsymbol{\mu})(Y-b)] \\
		\operatorname{Cov}(\mathbf{X})Q^{\top}
		\begin{pmatrix}
			\alpha \\
			\mathbf{0}	
		\end{pmatrix}=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)] 
	\end{gather*}
	所以$Q^{\top}
	\begin{pmatrix}
		\alpha \\
		\mathbf{0}
	\end{pmatrix}$满足预测方程，即：
	\begin{equation*}
		L(Y|\mathbf{X})=
		\begin{pmatrix}
			\alpha \\
			\mathbf{0}
		\end{pmatrix}^{\top}Q(\mathbf{X}-\boldsymbol{\mu})+b=
		\begin{pmatrix}
		\alpha \\
		\mathbf{0}
		\end{pmatrix}^{\top}\mathbf{Z}+b=\alpha^{\top}\varepsilon+b
	\end{equation*}\par
	(5)由(3)(4)和\cref{prop:CovMat}(2)立即可得。\par
	(6)由(2)的证明过程可知若$L(Y|\mathbf{X})=\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$是最佳线性预测，则对任意的$\beta\in\mathbb{R}^{n}$，有：
	\begin{equation*}
		\operatorname{E}\{[Y-b-\beta^{\top}(\mathbf{X}-\boldsymbol{\mu})]^2\}=\operatorname{E}[(Y-b)^2]+\operatorname{E}\{[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\}
	\end{equation*}
	若$\beta^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$也是最佳线性预测，由定义即可得：
	\begin{equation*}
		\operatorname{E}\{[(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})]^2\}=0
	\end{equation*}
	由\cref{prop:NonnegativeMeasurableIntegral}(9)可得此时$(\alpha^{\top}-\beta^{\top})(\mathbf{X}-\boldsymbol{\mu})=\mathbf{0}\;$a.e.，即
	\begin{equation*}
		\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b=\beta^{\top}(\mathbf{X}-\boldsymbol{\mu})+b,\quad a.e.
	\end{equation*}
	反之若上式成立，则由\cref{prop:NonnegativeMeasurableIntegral}(9)可得此时上上式成立，根据定义即可得到$\beta^{\top}(\mathbf{X}-\boldsymbol{\mu})+b$是最佳线性预测。\par
	(7)此时预测方程有解$\alpha=\mathbf{0}$，由(2)(6)可知$L(Y|\mathbf{X})=b\;$a.e.。\par
	(8)由最佳线性预测的定义和(6)立即可得。\par
	(9)由\cref{prop:MeasurableIntegral}(5)可得：
	\begin{align*}
		\operatorname{E}\{(\mathbf{X}-\boldsymbol{\mu})[Y-a^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]\}&=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]-\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})a^{\top}(\mathbf{X}-\boldsymbol{\mu}) \\
		&=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]-\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(\mathbf{X}-\boldsymbol{\mu})^{\top}\alpha] \\
		&=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]-\operatorname{Cov}(\mathbf{X})\alpha=\mathbf{0}
	\end{align*}
	上式即$\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-b)]$，所以预测方程的解满足上式，由(5)(6)可立即得出结论。\par
	(10)设$\operatorname{E}(Y_i)=b_i$，由(5)(2)可得$L(Y_i|\mathbf{X})=\alpha_i^{\top}(\mathbf{X}-\boldsymbol{\mu})+b_i$，其中$\alpha_i$是用$\mathbf{X}$对$Y_i$进行预测时的最佳线性预测的预测方程的解，由\cref{prop:MeasurableIntegral}(5)可得：
	\begin{align*}
		\operatorname{Cov}(\mathbf{X})\left(\sum_{i=1}^{n}k_i\alpha_i\right)&=\sum_{i=1}^{n}k_i\operatorname{Cov}(\mathbf{X})\alpha_i=\sum_{i=1}^{n}k_i\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y_i-b_i)] \\
		&=\operatorname{E}\left\{(\mathbf{X}-\boldsymbol{\mu})\left[\sum_{i=1}^{n}k_i(Y_i-b_i)\right]\right\} =\operatorname{E}\left[(\mathbf{X}-\boldsymbol{\mu})\left(\sum_{i=1}^{n}k_iY_i-\sum_{i=1}^{n}b_i\right)\right]
	\end{align*}
	由(2)(6)可立即得出结论。\par
	(11)设$\operatorname{E}(\mathbf{Z})=\boldsymbol{\nu},\;L(Y|\mathbf{X})=\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})+b,\;L(Y|\mathbf{Z})=\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})+b$，由(9)可得：
	\begin{equation*}
		\operatorname{E}\{(\mathbf{X}-\boldsymbol{\mu})[Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]\}=\mathbf{0},\quad
		\operatorname{E}\{(\mathbf{Z}-\boldsymbol{\nu})[Y-\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b]\}=\mathbf{0}
	\end{equation*}
	由\cref{prop:MeasurableIntegral}(5)可得：
	\begin{align*}
		&\operatorname{E}\left\{\left[
		\begin{pmatrix}
			\mathbf{X} \\
			\mathbf{Z}
		\end{pmatrix}-
		\begin{pmatrix}
			\boldsymbol{\mu} \\
			\boldsymbol{\nu}
		\end{pmatrix}
		\right][Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b-\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b]\right\} \\
		&=\operatorname{E}\left[
		\begin{pmatrix}
			(\mathbf{X}-\boldsymbol{\mu})[Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b-\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b] \\
			(\mathbf{Z}-\boldsymbol{\nu})[Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b-\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b]
		\end{pmatrix}
		\right] \\
		&=\operatorname{E}\left[
		\begin{pmatrix}
			(\mathbf{X}-\boldsymbol{\mu})[Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]-(\mathbf{X}-\boldsymbol{\mu})[\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b] \\
			(\mathbf{Z}-\boldsymbol{\nu})[Y-\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b]-(\mathbf{Z}-\boldsymbol{\nu})[\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]
		\end{pmatrix}
		\right] \\
		&=\operatorname{E}\left[
		\begin{pmatrix}
			(\mathbf{X}-\boldsymbol{\mu})[Y-\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b] \\
			(\mathbf{Z}-\boldsymbol{\nu})[Y-\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b]
		\end{pmatrix}
		\right]+\operatorname{E}\left[
		\begin{pmatrix}
			-(\mathbf{X}-\boldsymbol{\mu})[\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})-b] \\
			-(\mathbf{Z}-\boldsymbol{\nu})[\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})-b]
		\end{pmatrix}
		\right] \\
		&=\operatorname{E}\left[
		\begin{pmatrix}
			-(\mathbf{X}-\boldsymbol{\mu})[\beta^{\top}(\mathbf{Z}-\boldsymbol{\nu})]+b(\mathbf{X}-\boldsymbol{\mu}) \\
			-(\mathbf{Z}-\boldsymbol{\nu})[\alpha^{\top}(\mathbf{X}-\boldsymbol{\mu})]+b(\mathbf{X}-\boldsymbol{\mu})
		\end{pmatrix}
		\right] \\
		&=-
		\begin{pmatrix}
			\operatorname{Cov}(\mathbf{X},\mathbf{Z})\beta \\
			\operatorname{Cov}(\mathbf{Z},\mathbf{X})\alpha
		\end{pmatrix}+
		b
		\operatorname{E}\left[
		\begin{pmatrix}
			\mathbf{X}-\boldsymbol{\mu} \\
			\mathbf{Z}-\boldsymbol{\nu}
		\end{pmatrix}
		\right]=\mathbf{0}
	\end{align*}
	于是由(9)可得$L(Y|\mathbf{X},\mathbf{Z})=L(Y|\mathbf{X})+L(Y|\mathbf{Z})$。\par
	(12)令$\mathbf{Z}=(\seq{\mathbf{X}}{n-1}),\;\operatorname{E}(\mathbf{Z})=\boldsymbol{\nu}$，由(8)可得：
	\begin{equation*}
		\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(Y-\hat{Y})]=\mathbf{0},\quad\operatorname{E}[(\mathbf{Z}-\boldsymbol{\nu})(Y-\tilde{Y})]=\mathbf{0}
	\end{equation*}
	所以$\operatorname{E}[(\mathbf{Z}-\boldsymbol{\nu})(Y-\hat{Y})]=\mathbf{0}$，于是由\cref{prop:MeasurableIntegral}(5)可得：
	\begin{equation*}
		\operatorname{E}[(\mathbf{Z}-\boldsymbol{\nu})(Y-\tilde{Y})]-\operatorname{E}[(\mathbf{Z}-\boldsymbol{\nu})(Y-\hat{Y})]\operatorname{E}[(\mathbf{Z}-\boldsymbol{\nu})(Y-\tilde{Y}-Y+\hat{Y})]=\operatorname{E}[(\mathbf{Z}-\boldsymbol{\nu})(\hat{Y}-\tilde{Y})]=\mathbf{0}
	\end{equation*}
	所以$L(\hat{Y}|\seq{\mathbf{X}}{n-1})=\tilde{Y}$。因为$\tilde{Y}$也是对$Y$的线性预测，所以由最佳线性预测的定义可得$\operatorname{E}[(Y-\hat{Y})^2]\leqslant\operatorname{E}[(Y-\tilde{Y})^2]$。\par
	(13)显然。
\end{proof}
\begin{note}
	注意最佳线性预测是无偏估计，所以它的均方误差就等于方差。\info{均方误差与方差}
\end{note}
\subsubsection{样本最佳线性预测}
\begin{derivation}
	预测任务为：给定$\seq{x}{N}$，要求预测$x_{N+k}$。若使用$x_{N-n+1},x_{N-n+2},\dots,x_{N}$，令$\mathbf{X}=(X_{N-n+1},X_{N-n+2},\dots,X_N)^{\top},\;\operatorname{E}(X_t)=\mu,\;\hat{\mu}=\bar{x}_N$，则此时的预测方程为：
	\begin{gather*}
		\operatorname{Cov}(\mathbf{X})\alpha=\operatorname{E}[(\mathbf{X}-\boldsymbol{\mu})(X_{N+k}-\mu)] \\
		\Gamma_n\alpha=[\gamma(n+k-1),\gamma(n+k-2),\dots,\gamma(k)]^{\top}
	\end{gather*}
	样本预测方程为：
	\begin{equation*}
		\hat{\Gamma}_n\alpha=[\hat{\gamma}(n+k-1),\hat{\gamma}(n+k-2),\dots,\hat{\gamma}(k)]^{\top}
	\end{equation*}
	由\cref{theo:StationarySeriesAutoCovariancePE}(3)可知以$\dfrac{1}{n}$为分母构成的自协方差矩阵$\hat{\Gamma}_n$是正定的，根据\cref{theo:PositiveDefinite}(6)可知$\hat{\Gamma}_n$可逆，所以有$\alpha=\hat{\Gamma}_n^{-1}[\hat{\gamma}(n+k-1),\hat{\gamma}(n+k-2),\dots,\hat{\gamma}(k)]^{\top}$，最佳线性预测的预测值即为：
	\begin{equation*}
		\hat{X}_{N+k}=\alpha^{\top}(x_{N-n+1}-\hat{\mu},x_{N-n+2}-\hat{\mu},\dots,x_{N}-\hat{\mu})^{\top}+\hat{\mu}
	\end{equation*}
	此时必须满足$N\leqslant n+k-1$。
\end{derivation}

\subsection{最佳预测}
\begin{definition}
	设$Y$是方差有限的随机变量，$\mathbf{X}=(\seq{\mathbf{X}}{n})^{\top}$是各分量方差有限的随机向量，令：
	\begin{equation*}
		M=\overline{\operatorname{sp}}\left\{g(\mathbf{X})|\operatorname{E}[g^2(\mathbf{X})]<+\infty,\;g(\cdot)\text{是可测函数}\right\}
	\end{equation*}
	称：
	\begin{equation*}
		L(Y|M)=\mathcal{P}_M(\mathbf{X})
	\end{equation*}
	是用$\mathbf{X}$对$Y$进行预测时的\textbf{最佳预测}，其中$\mathcal{P}_M$是向$M$的投影算子。
\end{definition}
\begin{property}
	设$Y$是方差有限的随机变量，$\mathbf{X}=(\seq{\mathbf{X}}{n})^{\top}$是各分量方差有限的随机向量，$\operatorname{E}(\mathbf{X})=\boldsymbol{\mu}$。用$\mathbf{X}$对$Y$进行预测时的最佳预测具有如下性质：
	\begin{enumerate}
		\item 从方差的角度，最佳预测优于最佳线性预测；
		\item 若$(\mathbf{X},Y)\sim\operatorname{N}_{n+1}(\boldsymbol{\mu},\Sigma)$，则最佳预测$L(Y|M)$与最佳线性预测$L(Y|\mathbf{X})$相同。
	\end{enumerate}
\end{property}
\begin{proof}
	(1)\info{写完高概回来修改这边，整个时间序列的Hilbert空间理论}\par
	(2)由\cref{prop:BestLinearForcast}(1)可得$\operatorname{E}[Y-L(Y|\mathbf{X})]=0$，显然有$\operatorname{E}(\mathbf{X}-\boldsymbol{\mu})=\mathbf{0}$。由\cref{prop:BestLinearForcast}(9)可得此时$Y-L(Y|\mathbf{X})$与$\mathbf{X}-\boldsymbol{\mu}$不相关，根据\cref{prop:MultiNormal}(8)可知$Y-L(Y|\mathbf{X})$与$\mathbf{X}-\boldsymbol{\mu}$独立，于是$Y-L(Y|\mathbf{X})$与$M$中的任何元素都独立。对任意的$\alpha\in M$，由\cref{prop:CovMat}(6)可得$\operatorname{E}\{\alpha[Y-L(Y|\mathbf{X})]\}=\operatorname{E}(\alpha)\operatorname{E}[Y-L(Y|\mathbf{X})]=0$，所以$Y-L(Y|\mathbf{X})\perp M$。因为$L(Y|\mathbf{X})\in M$，由最佳预测的定义可得$L(Y|\mathbf{X})=L(Y|M)$。
\end{proof}