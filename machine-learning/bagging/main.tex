\chapter{集成学习}

对分类变量绘制分布图（count plot）及其与结局变量关系的箱线图或小提琴图，主要目的在于进行建模前的数据结构诊断，而非直接用于统计推断。分布图能够直观反映各类别的样本量规模与平衡性，从而识别样本量过小或高度不均衡的类别。由于回归或分组比较中类别效应的估计依赖于该类别内部的样本信息，当某一类别样本量不足时，其参数估计往往由少数观测值主导，估计方差显著增大，使结果对数据扰动高度敏感，表现为系数不稳定或显著性结论缺乏稳健性。通过在建模前识别此类问题，可以在分析阶段采取合并类别、重新编码或调整模型设定等措施，从而避免由样本结构缺陷引入的伪差异或误导性结论。与此同时，结局变量在不同类别下的箱线图或小提琴图能够揭示各类别内部结局分布的中心位置、离散程度及分布形态差异，从而帮助判断类别之间是否存在有序趋势、是否可能存在阈值效应，并为分类变量的编码方式（如有序编码或哑变量）提供依据；当不同类别的分布宽度、四分位距或尾部特征存在系统性差异时，意味着结局变量的条件方差随类别变化，提示潜在的异方差问题。该信息可在模型拟合前被直观识别，从而为是否采用稳健标准误、加权回归或其他模型修正提供依据。因此，此类图形的核心价值在于通过可视化方式理解样本信息量与变异结构，指导分类变量的编码方式与模型设定，并降低参数估计不稳定性，提高后续统计推断的可靠性，而非作为最终结论的直接证据。

绘制连续型变量的相关性热图，主要目的是在建模之前整体把握变量之间的线性依赖结构，而不是为了直接判断变量是否“重要”。通过热图可以直观识别哪些变量之间存在较强的正相关或负相关，从而判断是否存在潜在的冗余信息或多重共线性风险。如果多个自变量之间高度相关，它们在回归模型中往往会竞争解释同一部分变异，导致参数估计不稳定、标准误增大或系数符号不直观。此外，将结局变量一并纳入相关性分析，可以帮助形成对变量–结局关系强弱的初步认识，但该相关性仅反映边际线性关系，不能替代多变量模型中的条件效应。因此，相关性热图更像是一种“结构地图”，用于理解数据的整体关联格局、指导变量筛选与建模策略，而非用于得出因果或显著性结论。

本章介绍\gls{EnsembleLearning}算法。首先介绍信息量与信息熵，然后介绍两种主流的大类方法，并对每个大类内部的具体算法作阐释。

\input{machine-learning/bagging/information-theory}
\input{machine-learning/bagging/decision-tree}