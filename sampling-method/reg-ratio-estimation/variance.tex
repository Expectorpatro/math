\section{方差}
\subsection{回归估计的方差}
\begin{theorem}
	回归估计的方差为：
	\begin{equation*}
		Var(\hat{\mu}_{Y_{reg}})=Var(\bar{d})=\left(1-\frac{n}{N}\right)\frac{\sigma_d^2}{n}=\left(1-\frac{n}{N}\right)\frac{(1-R^2)\sigma_Y^2}{n}
	\end{equation*}
\end{theorem}
定义$e_i=y_i-(\hat{B}_1x_i+\hat{B}_0)$可得：
\begin{equation*}
	\widehat{Var}(\hat{\mu}_{Y_{reg}})=\left(1-\frac{n}{N}\right)\frac{s_e^2}{n}
\end{equation*}
这里$s_e^2$可取两种计算公式：
\begin{equation*}
	s_e^2=\frac{1}{n-1}\sum_{i=1}^ne_i^2=\left(1-\frac{n}{N}\right)\frac{(1-\hat{R}^2)s_y^2}{n},\quad
	s_e^2=\frac{1}{n-2}\sum_{i=1}^ne_i^2
\end{equation*}
第二种是考虑回归估计有两个待估参数，自由度为$n-2$，这样子做修正了回归中自由度的问题。\par
由上述总结：
\begin{gather*}
	\widehat{Var_1}(\hat{\mu}_{Y_{reg}})=\left(1-\frac{n}{N}\right)\frac{1}{n}\frac{1}{n-1}\sum_{i=1}^n\left[y_i-(\hat{B}_1x_i+\hat{B}_0)\right]^2 \\
	\widehat{Var_2}(\hat{\mu}_{Y_{reg}})=\left(1-\frac{n}{N}\right)\frac{1}{n}\frac{1}{n-2}\sum_{i=1}^n\left[y_i-(\hat{B}_1x_i+\hat{B}_0)\right]^2 
\end{gather*}

\subsection{比例估计的方差}
由Delta method（见\cref{sec:deltamethod}），注意到关系：
\begin{gather*}
	\hat{B}=\frac{\bar{y}}{\bar{x}}=g(\bar{x},\bar{y}) \\
	\hat{\mu}_{Yr}=\hat{B}\mu_X=g(\hat{B}) \\
	\hat{\tau}_{Yr}=\hat{\mu}_{Yr}\frac{\tau_X}{\mu_X}=\hat{\mu}_{Yr}N
\end{gather*}
可得以下比例估计量的近似方差($R=Corr(X,Y)$)：
\begin{gather*}
	Var(\hat{B})\approx\left(1-\frac{n}{N}\right)\frac{\sigma_Y^2-2BR\sigma_X\sigma_Y+B^2\sigma_X^2}{n\mu_X^2}=\left(1-\frac{n}{N}\right)\frac{\sigma_\varepsilon^2}{n\mu_X^2} \\
	\widehat{Var}(\hat{B})\approx\left(1-\frac{n}{N}\right)\frac{s_y^2-2\hat{B}\hat{R}s_xs_y+\hat{B}^2s_x^2}{n\bar{x}^2}=\left(1-\frac{n}{N}\right)\frac{s_e^2}{n\bar{x}^2} \\
	Var(\hat{\mu}_{Yr})\approx\left(1-\frac{n}{N}\right)\frac{\sigma_Y^2-2BR\sigma_X\sigma_Y+B^2\sigma_X^2}{n}=\left(1-\frac{n}{N}\right)\frac{\sigma_\varepsilon^2}{n}  \\
	\widehat{Var_1}(\hat{\mu}_{Yr})\approx\left(1-\frac{n}{N}\right)\frac{s_y^2-2\hat{B}\hat{R}s_xs_y+\hat{B}^2s_x^2}{n}=\left(1-\frac{n}{N}\right)\frac{s_e^2}{n}  \\
	Var(\hat{\tau}_{Yr})\approx N\left(N-n\right)\frac{\sigma_Y^2-2BR\sigma_X\sigma_Y+B^2\sigma_X^2}{n}=N(N-n)\frac{\sigma_\varepsilon^2}{n} \\
	\widehat{Var_1}(\hat{\tau}_{Yr})\approx N(N-n)\frac{s_y^2-2\hat{B}\hat{R}s_xs_y+\hat{B}^2s_x^2}{n}=N(N-n)\frac{s_e^2}{n}
\end{gather*}
再给出第二种总体均值、总体总量比例估计量抽样分布方差的估计：
\begin{gather*}
	\widehat{Var_2}(\hat{\mu}_{Yr})=\widehat{Var}(\hat{B}\mu_X)=\widehat{Var}(\hat{B})\mu_X^2\approx\left(1-\frac{n}{N}\right)\left(\frac{\mu_X}{\bar{x}}\right)^2\frac{s_e^2}{n} \\
	\widehat{Var_2}(\hat{\tau}_{Yr})\approx N(N-n)\left(\frac{\mu_X}{\bar{x}}\right)^2\frac{s_e^2}{n} 
\end{gather*}
下给出上述公式中所有等式的推导。
\begin{proof}
	从模型的角度，根据MSE的估计来看（最后一行是使用了SRS均值的方差公式）：
	\begin{gather*}
		\begin{aligned}
			Var(\hat{\mu}_{Yr})&\approx MSE(\hat{\mu}_{Yr})
			\approx E\left[(\bar{y}-B\bar{x})^2\right] \\
			&=E\left[\left(\frac{1}{n}\sum_{i=1}^ny_i-B\frac{1}{n}\sum_{i=1}^nx_i\right)^2\right] \\
			&=E\left\{\left[\frac{1}{n}\sum_{i=1}^n(y_i-Bx_i)\right]^2\right\}
		\end{aligned} \\
		\varepsilon_i=y_i-Bx_i,\;\mu_\varepsilon=E(\varepsilon_i)=0 \\
		\begin{aligned}
			Var(\hat{\mu}_{Yr})
			&\approx E\left\{\left[\frac{1}{n}\sum_{i=1}^n(y_i-Bx_i)\right]^2\right\} \\
			&=E\left[(\bar{\varepsilon})^2\right] \\
			&=E\left[(\bar{\varepsilon}-0)^2\right] \\
			&=E\left[(\bar{\varepsilon}-\mu_\varepsilon)^2\right] \\
			&=Var(\bar{\varepsilon}) \\
			&=\left(1-\frac{n}{N}\right)\frac{\sigma_\varepsilon^2}{n}
		\end{aligned}
	\end{gather*}
	对于$\sigma_\varepsilon^2$：
	\begin{align*}
		\sigma_\varepsilon^2
		&=\frac{1}{N-1}\left[\sum_{i=1}^Ny_i^2+B^2\sum_{i=1}^Nx_i^2-2B\sum_{i=1}^Nx_iyi\right] \\
		&=\frac{1}{N-1}\left[\sum_{i=1}^N(y_i-\mu_Y+\mu_Y)^2+B^2\sum_{i=1}^N(x_i-\mu_X+\mu_X)^2-2B\sum_{i=1}^Nx_iyi\right] \\
		&=\frac{1}{N-1}\left[\sum_{i=1}^N(y_i-\mu_Y)^2+2\sum_{i=1}^N(y_i-\mu_Y)\mu_Y+N\mu_Y^2\right.\\
		&\left.\qquad+B^2\sum_{i=1}^N(x_i-\mu_X)^2+2B^2\sum_{i=1}^N(x_i-\mu_X)\mu_X+B^2N\mu_X^2-2B\sum_{i=1}^Nx_iy_i\right] \\
		&=\sigma_Y^2+B^2\sigma_X^2+\frac{1}{N-1}\left[N\mu_Y^2+B^2N\mu_X^2-2B\sum_{i=1}^Nx_iy_i\right] \\
		&=\sigma_Y^2+B^2\sigma_X^2+\frac{1}{N-1}\left[N\mu_Y^2+B^2N\mu_X^2-2B\sum_{i=1}^N(x_i-\mu_X+\mu_X)(y_i-\mu_Y+\mu_Y)\right] \\
		&=\sigma_Y^2+B^2\sigma_X^2+\frac{1}{N-1}\left[N\mu_Y^2+B^2N\mu_X^2-2B\sum_{i=1}^N(x_i-\mu_X)(y_i-\mu_Y)-2BN\mu_X\mu_Y\right] \\
		&=\sigma_Y^2+B^2\sigma_X^2-2BCov(X,Y)+\frac{1}{N-1}\left[N\mu_Y^2+B^2N\mu_X^2-2BN\mu_X\mu_Y\right]
	\end{align*}
	因为：
	\begin{equation*}
		B=\frac{\mu_Y}{\mu_X}
	\end{equation*}
	所以：
	\begin{align*}
		N\mu_Y^2+B^2N\mu_X^2-2BN\mu_X\mu_Y
		&=N\mu_Y^2+\frac{\mu_Y^2}{\mu_X^2}N\mu_X^2-2\frac{\mu_Y}{\mu_X}N\mu_X\mu_Y \\
		&=2N\mu_Y^2-2N\mu_Y^2 \\
		&=0
	\end{align*}
	也就有：
	\begin{equation*}
		\sigma_\varepsilon^2=\sigma_Y^2-2BR\sigma_X\sigma_Y+B^2\sigma_X^2
	\end{equation*}
	令$e_i=y_i-\hat{B}x_i$，将它看作为$\varepsilon_i$的估计，则有：
	\begin{equation*}
		s_e^2 =s_y^2-2\hat{B}\hat{R}s_xs_y+\hat{B}^2s_x^2\qedhere
	\end{equation*}
\end{proof}
